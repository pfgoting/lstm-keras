{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Example script showing how to use stateful RNNs\n",
    "to model long sequences efficiently.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser2(x):\n",
    "    return pd.datetime.strptime(x,'%Y-%m')\n",
    "airline = 'international-airline-passengers.csv'\n",
    "series = pd.read_csv(airline, header=0,\n",
    "                 parse_dates=[0], index_col=0, squeeze=True, date_parser=parser2)\n",
    "# create X/y pairs\n",
    "df = pd.concat([series.shift(1), series], axis=1)\n",
    "df.dropna(inplace=True)\n",
    "# convert to LSTM friendly format\n",
    "values = df.values\n",
    "# split data into train and test\n",
    "train_size = int(len(df) * 0.67)\n",
    "test_size = len(df) - train_size\n",
    "X,Y = values[:,0],values[:,1]\n",
    "# train, test = series[0:train_size], series[train_size:len(series)]\n",
    "trainX, trainY = X[0:train_size], Y[0:train_size]\n",
    "testX, testY = X[-test_size:len(values)], Y[-test_size:len(values)]\n",
    "trainX,testX = trainX.reshape(len(trainX), 1, 1), testX.reshape(len(testX), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Data...\n",
      "Input shape: (50000, 1, 1)\n",
      "Output shape: (50000, 1)\n",
      "Creating Model...\n",
      "Training\n",
      "Epoch 0 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 43573.5730 - val_loss: 101160.1469\n",
      "Epoch 1 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 41479.0843 - val_loss: 98418.3766\n",
      "Epoch 2 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 39796.7376 - val_loss: 95711.8094\n",
      "Epoch 3 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 38161.4284 - val_loss: 93044.8492\n",
      "Epoch 4 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 36567.4615 - val_loss: 90419.0773\n",
      "Epoch 5 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 35016.1167 - val_loss: 87835.4312\n",
      "Epoch 6 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 33504.7788 - val_loss: 85294.3883\n",
      "Epoch 7 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 32033.5381 - val_loss: 82796.2836\n",
      "Epoch 8 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 30602.5106 - val_loss: 80341.4648\n",
      "Epoch 9 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 29212.8841 - val_loss: 77930.2281\n",
      "Epoch 10 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 27864.9324 - val_loss: 75562.9000\n",
      "Epoch 11 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 26558.7486 - val_loss: 73239.7695\n",
      "Epoch 12 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 25293.7388 - val_loss: 70961.0984\n",
      "Epoch 13 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 24069.7890 - val_loss: 68727.1578\n",
      "Epoch 14 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 22886.7673 - val_loss: 66538.2406\n",
      "Epoch 15 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 21744.6205 - val_loss: 64394.6586\n",
      "Epoch 16 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 20643.2070 - val_loss: 62296.7438\n",
      "Epoch 17 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 19582.4648 - val_loss: 60244.8594\n",
      "Epoch 18 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 18562.3592 - val_loss: 58239.4066\n",
      "Epoch 19 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 17582.8472 - val_loss: 56280.8227\n",
      "Epoch 20 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 16643.8808 - val_loss: 54369.6090\n",
      "Epoch 21 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 15745.3807 - val_loss: 52506.2629\n",
      "Epoch 22 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 14887.2506 - val_loss: 50691.3773\n",
      "Epoch 23 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 14069.3761 - val_loss: 48925.5551\n",
      "Epoch 24 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 13291.6044 - val_loss: 47209.4789\n",
      "Epoch 25 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 12553.7431 - val_loss: 45543.8441\n",
      "Epoch 26 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 11855.5459 - val_loss: 43929.4219\n",
      "Epoch 27 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 11196.7341 - val_loss: 42366.9941\n",
      "Epoch 28 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 10576.9385 - val_loss: 40857.4004\n",
      "Epoch 29 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9995.7375 - val_loss: 39401.4324\n",
      "Epoch 30 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9452.5739 - val_loss: 37999.8504\n",
      "Epoch 31 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8946.8057 - val_loss: 36653.4578\n",
      "Epoch 32 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8477.6735 - val_loss: 35362.8654\n",
      "Epoch 33 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8044.2715 - val_loss: 34128.6059\n",
      "Epoch 34 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7645.5587 - val_loss: 32951.0105\n",
      "Epoch 35 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7280.3197 - val_loss: 31830.1625\n",
      "Epoch 36 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6947.2111 - val_loss: 30765.9664\n",
      "Epoch 37 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6644.7215 - val_loss: 29757.8381\n",
      "Epoch 38 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6371.2018 - val_loss: 28804.9369\n",
      "Epoch 39 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6124.9043 - val_loss: 27906.0959\n",
      "Epoch 40 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5903.9739 - val_loss: 27059.7102\n",
      "Epoch 41 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5706.5188 - val_loss: 26263.9410\n",
      "Epoch 42 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5530.1896 - val_loss: 25516.4268\n",
      "Epoch 43 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5373.2954 - val_loss: 24814.9641\n",
      "Epoch 44 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5234.0844 - val_loss: 24157.1570\n",
      "Epoch 45 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5110.8915 - val_loss: 23540.7042\n",
      "Epoch 46 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5002.1558 - val_loss: 22963.2346\n",
      "Epoch 47 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4906.4239 - val_loss: 22422.4310\n",
      "Epoch 48 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4822.3455 - val_loss: 21916.0634\n",
      "Epoch 49 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4749.3296 - val_loss: 21442.2863\n",
      "Epoch 50 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4685.0449 - val_loss: 20998.7460\n",
      "Epoch 51 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4629.0385 - val_loss: 20583.5081\n",
      "Epoch 52 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 4580.3763 - val_loss: 20194.7306\n",
      "Epoch 53 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4538.1320 - val_loss: 19830.6472\n",
      "Epoch 54 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4502.5040 - val_loss: 19489.9673\n",
      "Epoch 55 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4471.2109 - val_loss: 19170.8386299.77\n",
      "Epoch 56 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4445.1270 - val_loss: 18872.1124\n",
      "Epoch 57 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4422.2020 - val_loss: 18592.1515\n",
      "Epoch 58 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4402.6203 - val_loss: 18329.6820\n",
      "Epoch 59 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4387.0430 - val_loss: 18083.8750\n",
      "Epoch 60 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4373.0326 - val_loss: 17853.2964\n",
      "Epoch 61 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4362.2994 - val_loss: 17637.2360\n",
      "Epoch 62 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4352.3619 - val_loss: 17434.4191\n",
      "Epoch 63 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4345.3295 - val_loss: 17244.3330\n",
      "Epoch 64 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4339.2605 - val_loss: 17066.0785\n",
      "Epoch 65 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4332.9016 - val_loss: 16898.5184\n",
      "Epoch 66 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4632.4720 - val_loss: 18667.0203\n",
      "Epoch 67 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6360.3115 - val_loss: 27467.7645\n",
      "Epoch 68 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 10768.9143 - val_loss: 41063.3410\n",
      "Epoch 69 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 10100.1784 - val_loss: 39612.6984\n",
      "Epoch 70 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9544.1241 - val_loss: 38204.2176\n",
      "Epoch 71 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9027.5195 - val_loss: 36833.1129\n",
      "Epoch 72 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8530.0353 - val_loss: 35517.3891\n",
      "Epoch 73 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8102.4845 - val_loss: 34218.7578\n",
      "Epoch 74 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 10117.1230 - val_loss: 39557.2770\n",
      "Epoch 75 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9496.5583 - val_loss: 38151.0414\n",
      "Epoch 76 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8983.6883 - val_loss: 36795.7766\n",
      "Epoch 77 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8565.2336 - val_loss: 35459.7391\n",
      "Epoch 78 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8100.5633 - val_loss: 34152.1662\n",
      "Epoch 79 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7635.4280 - val_loss: 32901.0596\n",
      "Epoch 80 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7230.6086 - val_loss: 31694.9334\n",
      "Epoch 81 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9297.4349 - val_loss: 37507.5387\n",
      "Epoch 82 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8757.5777 - val_loss: 36178.2697\n",
      "Epoch 83 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8296.6096 - val_loss: 34900.9043\n",
      "Epoch 84 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7897.3088 - val_loss: 33635.2189\n",
      "Epoch 85 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7851.5343 - val_loss: 32381.0207\n",
      "Epoch 86 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9821.1354 - val_loss: 38731.5699\n",
      "Epoch 87 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9244.1513 - val_loss: 37331.3980\n",
      "Epoch 88 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8696.2004 - val_loss: 36005.5830\n",
      "Epoch 89 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8237.3018 - val_loss: 34731.4549\n",
      "Epoch 90 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7830.2351 - val_loss: 33479.2914\n",
      "Epoch 91 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7559.3453 - val_loss: 32219.3822\n",
      "Epoch 92 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9431.9848 - val_loss: 37247.1777\n",
      "Epoch 93 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8672.2790 - val_loss: 35952.3541\n",
      "Epoch 94 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8231.2900 - val_loss: 34696.6023\n",
      "Epoch 95 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9379.2704 - val_loss: 37790.4062\n",
      "Epoch 96 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8862.2921 - val_loss: 36474.8432\n",
      "Epoch 97 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8403.2481 - val_loss: 35207.1387\n",
      "Epoch 98 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8011.3314 - val_loss: 33950.7932\n",
      "Epoch 99 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 9184.3390 - val_loss: 37148.1277\n",
      "Epoch 100 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8662.6805 - val_loss: 35840.5162\n",
      "Epoch 101 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 8188.2103 - val_loss: 34600.7807\n",
      "Epoch 102 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7539.4084 - val_loss: 31935.1764\n",
      "Epoch 103 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6957.9763 - val_loss: 30274.8459\n",
      "Epoch 104 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6417.3482 - val_loss: 29170.5855\n",
      "Epoch 105 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 5195.6360 - val_loss: 24855.6389\n",
      "Epoch 106 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6016.6210 - val_loss: 27722.6195\n",
      "Epoch 107 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5212.8652 - val_loss: 24904.5766\n",
      "Epoch 108 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5674.8898 - val_loss: 26433.9674\n",
      "Epoch 109 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5150.8083 - val_loss: 25089.3881\n",
      "Epoch 110 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5985.5545 - val_loss: 27733.3811\n",
      "Epoch 111 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7046.5494 - val_loss: 31229.7641\n",
      "Epoch 112 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6711.9509 - val_loss: 30238.4080\n",
      "Epoch 113 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6405.8238 - val_loss: 29278.8617\n",
      "Epoch 114 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7391.4593 - val_loss: 28321.8641\n",
      "Epoch 115 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6774.4342 - val_loss: 28908.6840\n",
      "Epoch 116 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 7387.6425 - val_loss: 32180.4117\n",
      "Epoch 117 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6680.9673 - val_loss: 29639.8152\n",
      "Epoch 118 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6072.4889 - val_loss: 28238.6031\n",
      "Epoch 119 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5801.2551 - val_loss: 27414.2652\n",
      "Epoch 120 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5545.2664 - val_loss: 26608.5266\n",
      "Epoch 121 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6856.3973 - val_loss: 30686.1063\n",
      "Epoch 122 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6550.6044 - val_loss: 29802.1338\n",
      "Epoch 123 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6286.8614 - val_loss: 28948.0982\n",
      "Epoch 124 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6025.8558 - val_loss: 28112.5525\n",
      "Epoch 125 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5473.7940 - val_loss: 25780.9979\n",
      "Epoch 126 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4892.3263 - val_loss: 24294.0672\n",
      "Epoch 127 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4591.0039 - val_loss: 23059.2438\n",
      "Epoch 128 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4264.0206 - val_loss: 21990.3019\n",
      "Epoch 129 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5487.8943 - val_loss: 26260.5236\n",
      "Epoch 130 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5230.2589 - val_loss: 25543.1740\n",
      "Epoch 131 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5081.3986 - val_loss: 24860.1850\n",
      "Epoch 132 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4913.3759 - val_loss: 24436.1172\n",
      "Epoch 133 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4736.7449 - val_loss: 23568.5449\n",
      "Epoch 134 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4489.0763 - val_loss: 22773.9005\n",
      "Epoch 135 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4379.2577 - val_loss: 22448.3121\n",
      "Epoch 136 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5278.1497 - val_loss: 25151.8061\n",
      "Epoch 137 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4753.4256 - val_loss: 23770.9159\n",
      "Epoch 138 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4690.8982 - val_loss: 23616.6015\n",
      "Epoch 139 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4539.5977 - val_loss: 23012.1399\n",
      "Epoch 140 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4467.7820 - val_loss: 22431.9016\n",
      "Epoch 141 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5821.3654 - val_loss: 27540.8678\n",
      "Epoch 142 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5622.6668 - val_loss: 26827.2467\n",
      "Epoch 143 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5407.3101 - val_loss: 26134.8922\n",
      "Epoch 144 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5225.4904 - val_loss: 25456.5104\n",
      "Epoch 145 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5009.6058 - val_loss: 24799.0650\n",
      "Epoch 146 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4911.7936 - val_loss: 24411.8285\n",
      "Epoch 147 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4754.5718 - val_loss: 23777.9081\n",
      "Epoch 148 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6635.6649 - val_loss: 29707.8951\n",
      "Epoch 149 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6249.7336 - val_loss: 28920.0508\n",
      "Epoch 150 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6108.9706 - val_loss: 28436.5115\n",
      "Epoch 151 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5871.6443 - val_loss: 27692.5555\n",
      "Epoch 152 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5640.0290 - val_loss: 26968.5705\n",
      "Epoch 153 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5577.6829 - val_loss: 26653.9357\n",
      "Epoch 154 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5346.3144 - val_loss: 25956.8512\n",
      "Epoch 155 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5146.8882 - val_loss: 25270.9711\n",
      "Epoch 156 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4980.8931 - val_loss: 24603.2951\n",
      "Epoch 157 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4782.2338 - val_loss: 23952.6468\n",
      "Epoch 158 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 4640.4004 - val_loss: 23317.1647\n",
      "Epoch 159 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4598.0595 - val_loss: 23156.4732\n",
      "Epoch 160 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4700.6649 - val_loss: 23683.5223\n",
      "Epoch 161 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4581.1019 - val_loss: 23048.5860\n",
      "Epoch 162 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4482.7273 - val_loss: 22929.2914\n",
      "Epoch 163 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6349.4936 - val_loss: 29141.4793\n",
      "Epoch 164 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 6047.1515 - val_loss: 28234.3350\n",
      "Epoch 165 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5797.9789 - val_loss: 27447.9727\n",
      "Epoch 166 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5576.5101 - val_loss: 26748.1430\n",
      "Epoch 167 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5362.6984 - val_loss: 26068.6242\n",
      "Epoch 168 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5214.3412 - val_loss: 25477.7902\n",
      "Epoch 169 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 5003.9503 - val_loss: 24832.1961\n",
      "Epoch 170 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4913.8167 - val_loss: 24455.0928\n",
      "Epoch 171 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4721.6624 - val_loss: 23837.8072\n",
      "Epoch 172 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4578.9493 - val_loss: 23235.7560\n",
      "Epoch 173 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4401.1969 - val_loss: 22655.1018\n",
      "Epoch 174 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4249.2451 - val_loss: 22092.7307\n",
      "Epoch 175 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4117.8462 - val_loss: 21543.0836\n",
      "Epoch 176 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3987.9799 - val_loss: 21007.3337\n",
      "Epoch 177 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3862.2334 - val_loss: 20484.1191\n",
      "Epoch 178 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3737.4601 - val_loss: 19978.4153\n",
      "Epoch 179 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3630.3226 - val_loss: 19484.4092\n",
      "Epoch 180 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3512.6867 - val_loss: 19008.2733\n",
      "Epoch 181 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3416.8335 - val_loss: 18540.1831\n",
      "Epoch 182 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3415.5454 - val_loss: 18407.2134\n",
      "Epoch 183 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3190.3735 - val_loss: 17151.8858\n",
      "Epoch 184 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3041.8987 - val_loss: 16445.9536\n",
      "Epoch 185 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2885.2327 - val_loss: 15830.4866\n",
      "Epoch 186 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2941.3335 - val_loss: 16169.8437\n",
      "Epoch 187 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2915.9109 - val_loss: 15878.8803\n",
      "Epoch 188 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2796.3890 - val_loss: 15565.3673\n",
      "Epoch 189 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2746.0487 - val_loss: 15289.9728\n",
      "Epoch 190 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2680.1734 - val_loss: 14993.4963\n",
      "Epoch 191 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2647.8569 - val_loss: 14734.7778\n",
      "Epoch 192 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2633.1063 - val_loss: 13990.1430\n",
      "Epoch 193 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2494.4258 - val_loss: 13301.7142\n",
      "Epoch 194 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2383.5974 - val_loss: 13024.5549\n",
      "Epoch 195 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2364.5404 - val_loss: 12756.3428\n",
      "Epoch 196 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2230.4048 - val_loss: 12500.8211\n",
      "Epoch 197 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3239.6702 - val_loss: 17667.2522\n",
      "Epoch 198 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3076.8025 - val_loss: 16904.0653\n",
      "Epoch 199 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2939.2067 - val_loss: 16105.9084\n",
      "Epoch 200 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2815.0244 - val_loss: 15666.7943\n",
      "Epoch 201 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2705.2174 - val_loss: 15332.2499\n",
      "Epoch 202 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2723.2188 - val_loss: 15024.0097\n",
      "Epoch 203 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2597.2470 - val_loss: 14726.7880\n",
      "Epoch 204 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2605.7558 - val_loss: 14437.3263\n",
      "Epoch 205 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2586.3833 - val_loss: 14120.7032\n",
      "Epoch 206 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2565.9937 - val_loss: 13839.9317\n",
      "Epoch 207 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2432.1530 - val_loss: 13574.2614\n",
      "Epoch 208 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2404.8130 - val_loss: 13319.1125\n",
      "Epoch 209 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2335.5965 - val_loss: 13074.0141\n",
      "Epoch 210 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2263.8344 - val_loss: 12831.8281\n",
      "Epoch 211 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2291.9399 - val_loss: 12696.9457\n",
      "Epoch 212 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2261.2769 - val_loss: 12726.7369\n",
      "Epoch 213 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2261.0409 - val_loss: 12503.2347\n",
      "Epoch 214 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2150.3274 - val_loss: 12275.1518\n",
      "Epoch 215 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2125.5184 - val_loss: 12069.6816\n",
      "Epoch 216 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2076.3516 - val_loss: 11862.1865\n",
      "Epoch 217 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2064.5223 - val_loss: 11671.6871\n",
      "Epoch 218 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2034.0384 - val_loss: 11478.0640\n",
      "Epoch 219 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2117.0907 - val_loss: 11665.8728\n",
      "Epoch 220 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2043.7983 - val_loss: 11477.5403\n",
      "Epoch 221 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2113.0960 - val_loss: 10845.9251\n",
      "Epoch 222 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1940.3698 - val_loss: 9962.6151\n",
      "Epoch 223 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2541.3840 - val_loss: 14005.4127\n",
      "Epoch 224 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2373.7766 - val_loss: 13563.5212\n",
      "Epoch 225 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2370.3786 - val_loss: 13321.5938\n",
      "Epoch 226 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2332.0529 - val_loss: 13198.9089\n",
      "Epoch 227 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2304.7993 - val_loss: 12968.0205\n",
      "Epoch 228 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2290.1680 - val_loss: 12724.8072\n",
      "Epoch 229 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2193.1541 - val_loss: 12464.9206\n",
      "Epoch 230 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2154.8606 - val_loss: 12220.5896\n",
      "Epoch 231 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2196.4159 - val_loss: 12093.7223\n",
      "Epoch 232 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2116.9077 - val_loss: 11778.3274\n",
      "Epoch 233 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2077.5991 - val_loss: 11563.9752\n",
      "Epoch 234 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2130.8338 - val_loss: 11391.4920\n",
      "Epoch 235 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2091.4702 - val_loss: 11156.3926\n",
      "Epoch 236 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1946.9876 - val_loss: 10988.8447\n",
      "Epoch 237 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2013.5170 - val_loss: 10835.8841\n",
      "Epoch 238 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2032.5305 - val_loss: 10985.7812\n",
      "Epoch 239 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1951.8621 - val_loss: 10591.4885\n",
      "Epoch 240 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2060.5506 - val_loss: 10381.3505\n",
      "Epoch 241 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2904.2039 - val_loss: 15957.3676\n",
      "Epoch 242 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2780.8901 - val_loss: 15651.3994\n",
      "Epoch 243 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2720.8295 - val_loss: 15376.2509\n",
      "Epoch 244 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2692.8293 - val_loss: 15076.5251\n",
      "Epoch 245 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2632.3682 - val_loss: 14802.9025\n",
      "Epoch 246 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2572.5570 - val_loss: 14543.0414\n",
      "Epoch 247 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2613.9626 - val_loss: 14285.8639\n",
      "Epoch 248 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2559.2509 - val_loss: 14293.6235\n",
      "Epoch 249 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2495.6514 - val_loss: 14018.1125\n",
      "Epoch 250 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2470.9516 - val_loss: 13774.8584\n",
      "Epoch 251 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2452.2332 - val_loss: 13705.7042\n",
      "Epoch 252 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2460.7773 - val_loss: 13433.3586\n",
      "Epoch 253 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2429.6650 - val_loss: 13172.0760\n",
      "Epoch 254 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2418.2545 - val_loss: 12927.4990\n",
      "Epoch 255 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2214.7444 - val_loss: 12705.6452\n",
      "Epoch 256 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2177.9477 - val_loss: 12489.6093\n",
      "Epoch 257 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2213.7879 - val_loss: 12288.8099\n",
      "Epoch 258 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2149.8044 - val_loss: 12109.9895\n",
      "Epoch 259 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2205.0193 - val_loss: 12455.8682\n",
      "Epoch 260 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2129.0833 - val_loss: 11760.1056\n",
      "Epoch 261 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2039.5073 - val_loss: 11621.7692\n",
      "Epoch 262 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1997.0993 - val_loss: 11528.1615\n",
      "Epoch 263 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1993.4807 - val_loss: 11333.7242\n",
      "Epoch 264 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 1996.8416 - val_loss: 11223.7327\n",
      "Epoch 265 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2083.7073 - val_loss: 11661.0133\n",
      "Epoch 266 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2021.4863 - val_loss: 11497.7362\n",
      "Epoch 267 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2017.9842 - val_loss: 11337.9551\n",
      "Epoch 268 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1964.2662 - val_loss: 11266.7391\n",
      "Epoch 269 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2012.7640 - val_loss: 11614.6952\n",
      "Epoch 270 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2015.9762 - val_loss: 11436.6675\n",
      "Epoch 271 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2059.3279 - val_loss: 11269.1289\n",
      "Epoch 272 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1950.0072 - val_loss: 11122.1049\n",
      "Epoch 273 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1950.7742 - val_loss: 10958.1298\n",
      "Epoch 274 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1980.8173 - val_loss: 10786.9603\n",
      "Epoch 275 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1979.0787 - val_loss: 10635.9503\n",
      "Epoch 276 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1860.1425 - val_loss: 10490.0526\n",
      "Epoch 277 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1884.1985 - val_loss: 10322.0874\n",
      "Epoch 278 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1933.8980 - val_loss: 10175.2479\n",
      "Epoch 279 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1788.8063 - val_loss: 10052.5945\n",
      "Epoch 280 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1754.8058 - val_loss: 9925.9468\n",
      "Epoch 281 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1793.5018 - val_loss: 9786.4447\n",
      "Epoch 282 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2005.4452 - val_loss: 9722.3446\n",
      "Epoch 283 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1843.2088 - val_loss: 9583.3988\n",
      "Epoch 284 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1745.6149 - val_loss: 9456.3288\n",
      "Epoch 285 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1789.6584 - val_loss: 10003.5444\n",
      "Epoch 286 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1713.9380 - val_loss: 9369.1374\n",
      "Epoch 287 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1872.9531 - val_loss: 9251.7107\n",
      "Epoch 288 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1759.8103 - val_loss: 9123.8797\n",
      "Epoch 289 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1691.3041 - val_loss: 8989.0228\n",
      "Epoch 290 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1855.7033 - val_loss: 8904.6835\n",
      "Epoch 291 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1670.4123 - val_loss: 8773.4465\n",
      "Epoch 292 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1614.5239 - val_loss: 8655.5888\n",
      "Epoch 293 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1689.3670 - val_loss: 8538.0744\n",
      "Epoch 294 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1681.7348 - val_loss: 8437.7007\n",
      "Epoch 295 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1678.9730 - val_loss: 8975.8540\n",
      "Epoch 296 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1920.1561 - val_loss: 8862.4013\n",
      "Epoch 297 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1798.7362 - val_loss: 9818.6937\n",
      "Epoch 298 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2063.9805 - val_loss: 9796.2822\n",
      "Epoch 299 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2120.7013 - val_loss: 9674.7708\n",
      "Epoch 300 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2106.5974 - val_loss: 9553.9760\n",
      "Epoch 301 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2664.5918 - val_loss: 12455.5809\n",
      "Epoch 302 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2889.4099 - val_loss: 12261.6587\n",
      "Epoch 303 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2636.5636 - val_loss: 12048.6386\n",
      "Epoch 304 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2586.4751 - val_loss: 11854.8630\n",
      "Epoch 305 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2529.4576 - val_loss: 11660.8980\n",
      "Epoch 306 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2610.6728 - val_loss: 11512.6561\n",
      "Epoch 307 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2500.8938 - val_loss: 11324.0784\n",
      "Epoch 308 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2342.0276 - val_loss: 11133.5349\n",
      "Epoch 309 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2458.3909 - val_loss: 10951.5390\n",
      "Epoch 310 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2361.9329 - val_loss: 10768.3571\n",
      "Epoch 311 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2355.0452 - val_loss: 10588.9362\n",
      "Epoch 312 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2345.3162 - val_loss: 10413.1176\n",
      "Epoch 313 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2159.5002 - val_loss: 10232.5128\n",
      "Epoch 314 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2102.7714 - val_loss: 10103.4809\n",
      "Epoch 315 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2252.4206 - val_loss: 10089.9450\n",
      "Epoch 316 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2191.1727 - val_loss: 9918.1024\n",
      "Epoch 317 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2378.7250 - val_loss: 9766.7659\n",
      "Epoch 318 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2153.4734 - val_loss: 9414.4828\n",
      "Epoch 319 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2304.0529 - val_loss: 9102.4394\n",
      "Epoch 320 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2039.2675 - val_loss: 8754.3823\n",
      "Epoch 321 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2260.0175 - val_loss: 8477.8823\n",
      "Epoch 322 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2104.7240 - val_loss: 8330.1604\n",
      "Epoch 323 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1844.0446 - val_loss: 8138.7430\n",
      "Epoch 324 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2034.7854 - val_loss: 8024.2006\n",
      "Epoch 325 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2310.3122 - val_loss: 7933.8394\n",
      "Epoch 326 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1971.5441 - val_loss: 7883.7159\n",
      "Epoch 327 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1831.8062 - val_loss: 7735.3296\n",
      "Epoch 328 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2163.1536 - val_loss: 7664.3948\n",
      "Epoch 329 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2671.5450 - val_loss: 13493.6255\n",
      "Epoch 330 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2722.9526 - val_loss: 13238.9644\n",
      "Epoch 331 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2576.6421 - val_loss: 12989.3626\n",
      "Epoch 332 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2416.1654 - val_loss: 12742.8140\n",
      "Epoch 333 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2369.8203 - val_loss: 11884.7380\n",
      "Epoch 334 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2309.1443 - val_loss: 11161.9364\n",
      "Epoch 335 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2193.0194 - val_loss: 10543.9337\n",
      "Epoch 336 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2341.7040 - val_loss: 10230.3159\n",
      "Epoch 337 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1940.9410 - val_loss: 10040.9007\n",
      "Epoch 338 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2555.8840 - val_loss: 9913.8395\n",
      "Epoch 339 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1956.5460 - val_loss: 9824.4480\n",
      "Epoch 340 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2740.6246 - val_loss: 13841.1731\n",
      "Epoch 341 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2264.5036 - val_loss: 11800.2912\n",
      "Epoch 342 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2401.0693 - val_loss: 10236.5488\n",
      "Epoch 343 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2007.1369 - val_loss: 9366.5261\n",
      "Epoch 344 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1943.5870 - val_loss: 9432.3552\n",
      "Epoch 345 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1997.7944 - val_loss: 9305.4915\n",
      "Epoch 346 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2221.1994 - val_loss: 9212.2354\n",
      "Epoch 347 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2009.3681 - val_loss: 9091.5098\n",
      "Epoch 348 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2284.8077 - val_loss: 9015.2825\n",
      "Epoch 349 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1980.0512 - val_loss: 8887.4973\n",
      "Epoch 350 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2367.3620 - val_loss: 8837.4666\n",
      "Epoch 351 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1999.4577 - val_loss: 8705.7683\n",
      "Epoch 352 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2240.3629 - val_loss: 9032.6967\n",
      "Epoch 353 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2054.1105 - val_loss: 8920.4500\n",
      "Epoch 354 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2410.5967 - val_loss: 8910.0319\n",
      "Epoch 355 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2000.1594 - val_loss: 8824.8747\n",
      "Epoch 356 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1932.9139 - val_loss: 8664.8826\n",
      "Epoch 357 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2191.5126 - val_loss: 8597.0870\n",
      "Epoch 358 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1879.7379 - val_loss: 8462.9316\n",
      "Epoch 359 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2029.6874 - val_loss: 8363.8643\n",
      "Epoch 360 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2066.9151 - val_loss: 8250.5308\n",
      "Epoch 361 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1975.0421 - val_loss: 8146.6243\n",
      "Epoch 362 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2042.9267 - val_loss: 8020.5169\n",
      "Epoch 363 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1931.8450 - val_loss: 7938.7420\n",
      "Epoch 364 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1896.5003 - val_loss: 7841.9603\n",
      "Epoch 365 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2019.2732 - val_loss: 7783.2324\n",
      "Epoch 366 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2027.2328 - val_loss: 7672.4380\n",
      "Epoch 367 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1994.1067 - val_loss: 7577.4883\n",
      "Epoch 368 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1649.9700 - val_loss: 7502.0254\n",
      "Epoch 369 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3285.3389 - val_loss: 7480.5641\n",
      "Epoch 370 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 1725.1180 - val_loss: 7426.1785\n",
      "Epoch 371 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1919.3839 - val_loss: 7353.7884\n",
      "Epoch 372 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1929.0139 - val_loss: 7193.6020\n",
      "Epoch 373 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2105.6907 - val_loss: 7508.8765\n",
      "Epoch 374 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2872.9518 - val_loss: 12350.3930\n",
      "Epoch 375 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2343.1380 - val_loss: 11340.3691\n",
      "Epoch 376 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2076.4438 - val_loss: 10461.5368\n",
      "Epoch 377 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2074.1968 - val_loss: 9959.3794\n",
      "Epoch 378 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2107.8813 - val_loss: 9829.8192\n",
      "Epoch 379 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2075.4123 - val_loss: 9716.1738\n",
      "Epoch 380 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2214.7090 - val_loss: 9603.8811\n",
      "Epoch 381 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2094.9291 - val_loss: 9495.7452\n",
      "Epoch 382 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2238.0284 - val_loss: 9373.8517\n",
      "Epoch 383 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2219.6146 - val_loss: 9349.7095\n",
      "Epoch 384 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2298.4650 - val_loss: 9248.8313\n",
      "Epoch 385 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2305.1355 - val_loss: 9158.0209\n",
      "Epoch 386 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2165.9621 - val_loss: 9054.2253\n",
      "Epoch 387 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2180.4186 - val_loss: 8958.0141\n",
      "Epoch 388 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2160.2733 - val_loss: 8865.0557\n",
      "Epoch 389 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2130.0772 - val_loss: 8777.9294\n",
      "Epoch 390 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2169.7173 - val_loss: 8681.6722\n",
      "Epoch 391 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2275.1447 - val_loss: 8591.0155\n",
      "Epoch 392 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2192.5058 - val_loss: 8500.8306\n",
      "Epoch 393 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2244.0950 - val_loss: 8418.2208\n",
      "Epoch 394 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2222.3231 - val_loss: 8369.2884\n",
      "Epoch 395 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2077.7290 - val_loss: 8255.5723\n",
      "Epoch 396 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2114.1572 - val_loss: 8145.6857\n",
      "Epoch 397 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1965.1131 - val_loss: 8086.2704\n",
      "Epoch 398 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1771.3827 - val_loss: 8012.8277\n",
      "Epoch 399 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1994.6099 - val_loss: 7923.9617\n",
      "Epoch 400 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2151.1895 - val_loss: 8006.8845\n",
      "Epoch 401 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1811.2741 - val_loss: 7793.1356\n",
      "Epoch 402 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2001.3115 - val_loss: 7716.0372\n",
      "Epoch 403 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1812.0033 - val_loss: 7586.2495\n",
      "Epoch 404 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1899.9945 - val_loss: 7532.9961\n",
      "Epoch 405 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1778.4901 - val_loss: 7432.9696\n",
      "Epoch 406 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1883.2457 - val_loss: 7369.3237\n",
      "Epoch 407 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1774.7111 - val_loss: 7300.6388\n",
      "Epoch 408 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1919.2599 - val_loss: 7237.4509\n",
      "Epoch 409 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1894.1639 - val_loss: 7152.3991\n",
      "Epoch 410 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2388.0989 - val_loss: 7322.0112\n",
      "Epoch 411 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1753.1783 - val_loss: 7159.4994\n",
      "Epoch 412 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2229.0461 - val_loss: 6969.4828\n",
      "Epoch 413 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2091.8041 - val_loss: 6923.5538\n",
      "Epoch 414 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2128.7776 - val_loss: 6846.6135\n",
      "Epoch 415 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2059.4428 - val_loss: 6846.9703\n",
      "Epoch 416 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2060.1256 - val_loss: 6792.0572\n",
      "Epoch 417 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2016.7160 - val_loss: 6713.0033\n",
      "Epoch 418 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1893.0245 - val_loss: 6653.1694\n",
      "Epoch 419 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1941.3911 - val_loss: 6668.2688\n",
      "Epoch 420 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1916.5377 - val_loss: 6515.8985\n",
      "Epoch 421 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1823.7553 - val_loss: 6425.2270\n",
      "Epoch 422 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1608.3474 - val_loss: 6351.1062\n",
      "Epoch 423 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2942.3934 - val_loss: 6414.8509\n",
      "Epoch 424 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1522.5528 - val_loss: 6224.8190\n",
      "Epoch 425 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2247.6244 - val_loss: 6278.2464\n",
      "Epoch 426 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1897.1986 - val_loss: 6324.8480\n",
      "Epoch 427 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1737.3128 - val_loss: 6192.3376\n",
      "Epoch 428 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1772.1405 - val_loss: 6011.5300\n",
      "Epoch 429 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2318.4512 - val_loss: 6379.8610\n",
      "Epoch 430 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2054.7065 - val_loss: 6303.5899\n",
      "Epoch 431 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2146.5261 - val_loss: 6226.5871\n",
      "Epoch 432 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2140.0830 - val_loss: 6260.8375\n",
      "Epoch 433 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1913.2260 - val_loss: 6242.9472\n",
      "Epoch 434 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2049.3308 - val_loss: 6160.3364\n",
      "Epoch 435 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2002.3837 - val_loss: 6492.3581\n",
      "Epoch 436 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1924.2154 - val_loss: 6538.1934\n",
      "Epoch 437 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1878.6068 - val_loss: 6382.6895\n",
      "Epoch 438 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1990.1866 - val_loss: 6330.9829\n",
      "Epoch 439 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1946.3167 - val_loss: 6255.4734\n",
      "Epoch 440 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2227.4113 - val_loss: 6299.2969\n",
      "Epoch 441 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2097.9257 - val_loss: 6289.5701\n",
      "Epoch 442 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2221.1505 - val_loss: 6114.1494\n",
      "Epoch 443 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2300.6360 - val_loss: 6059.4713\n",
      "Epoch 444 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2102.0308 - val_loss: 6142.7742\n",
      "Epoch 445 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2249.2944 - val_loss: 5986.6460\n",
      "Epoch 446 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2110.5795 - val_loss: 6021.0381\n",
      "Epoch 447 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2174.4663 - val_loss: 5967.7796\n",
      "Epoch 448 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2202.3199 - val_loss: 5884.2220\n",
      "Epoch 449 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2111.4124 - val_loss: 5909.6800\n",
      "Epoch 450 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2095.6389 - val_loss: 5859.9154\n",
      "Epoch 451 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2092.5907 - val_loss: 5847.3621\n",
      "Epoch 452 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2095.9919 - val_loss: 5706.5966\n",
      "Epoch 453 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1996.2720 - val_loss: 5848.8930\n",
      "Epoch 454 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1986.9744 - val_loss: 5637.1890\n",
      "Epoch 455 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1999.8617 - val_loss: 5711.4662\n",
      "Epoch 456 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1966.8883 - val_loss: 5652.0991\n",
      "Epoch 457 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1886.7348 - val_loss: 5642.2882\n",
      "Epoch 458 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1967.0587 - val_loss: 5615.6872\n",
      "Epoch 459 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1887.6815 - val_loss: 5602.0963\n",
      "Epoch 460 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1769.6092 - val_loss: 5676.5516\n",
      "Epoch 461 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1288.4173 - val_loss: 5108.9899\n",
      "Epoch 462 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1641.9592 - val_loss: 5467.3730\n",
      "Epoch 463 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1949.1389 - val_loss: 5207.0890\n",
      "Epoch 464 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1904.0927 - val_loss: 5401.1081\n",
      "Epoch 465 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1906.3816 - val_loss: 5274.9256\n",
      "Epoch 466 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1924.2696 - val_loss: 5169.5000\n",
      "Epoch 467 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1937.6313 - val_loss: 5349.7795\n",
      "Epoch 468 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1967.0804 - val_loss: 5061.7315\n",
      "Epoch 469 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2027.4875 - val_loss: 5104.2255\n",
      "Epoch 470 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1867.1387 - val_loss: 4913.7240\n",
      "Epoch 471 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1868.9151 - val_loss: 5137.1587\n",
      "Epoch 472 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1902.9315 - val_loss: 5278.3558\n",
      "Epoch 473 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1747.0286 - val_loss: 5062.9347\n",
      "Epoch 474 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2008.4210 - val_loss: 5092.7947\n",
      "Epoch 475 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1843.1882 - val_loss: 4962.7780\n",
      "Epoch 476 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2101.7069 - val_loss: 5139.9963\n",
      "Epoch 477 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2035.8241 - val_loss: 5142.1722\n",
      "Epoch 478 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2113.4413 - val_loss: 5213.3055\n",
      "Epoch 479 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1773.0745 - val_loss: 5069.4942\n",
      "Epoch 480 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2083.3765 - val_loss: 5341.3594\n",
      "Epoch 481 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1934.7545 - val_loss: 4763.5690\n",
      "Epoch 482 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2061.8771 - val_loss: 5083.8112\n",
      "Epoch 483 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1831.4617 - val_loss: 4892.9865\n",
      "Epoch 484 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2177.8270 - val_loss: 5199.8211\n",
      "Epoch 485 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1749.6229 - val_loss: 4705.0624\n",
      "Epoch 486 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1988.7518 - val_loss: 5086.8362\n",
      "Epoch 487 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1953.1182 - val_loss: 4874.3125\n",
      "Epoch 488 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2042.6411 - val_loss: 4852.4054\n",
      "Epoch 489 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1951.7846 - val_loss: 4745.9718\n",
      "Epoch 490 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2040.6393 - val_loss: 4571.3128\n",
      "Epoch 491 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2062.5688 - val_loss: 4546.2114\n",
      "Epoch 492 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2012.8576 - val_loss: 4478.1840\n",
      "Epoch 493 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1989.2193 - val_loss: 4418.9248\n",
      "Epoch 494 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2016.3903 - val_loss: 4359.7409\n",
      "Epoch 495 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1995.6577 - val_loss: 4462.5956\n",
      "Epoch 496 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2449.0735 - val_loss: 4505.8004\n",
      "Epoch 497 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2291.0875 - val_loss: 4701.1034\n",
      "Epoch 498 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2394.1166 - val_loss: 4524.7917\n",
      "Epoch 499 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2088.5568 - val_loss: 4633.7436\n",
      "Epoch 500 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2323.7690 - val_loss: 4658.1963\n",
      "Epoch 501 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1961.5767 - val_loss: 4576.8918\n",
      "Epoch 502 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2030.2984 - val_loss: 4628.1654\n",
      "Epoch 503 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1476.2069 - val_loss: 4315.6112\n",
      "Epoch 504 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3379.4597 - val_loss: 4789.0665\n",
      "Epoch 505 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1378.2357 - val_loss: 4806.8245\n",
      "Epoch 506 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2159.4642 - val_loss: 4746.7982\n",
      "Epoch 507 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2395.5888 - val_loss: 5032.9703\n",
      "Epoch 508 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1985.9875 - val_loss: 4986.8285\n",
      "Epoch 509 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1867.0738 - val_loss: 4929.8288\n",
      "Epoch 510 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2104.9256 - val_loss: 4748.3951\n",
      "Epoch 511 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2145.6522 - val_loss: 4888.0685\n",
      "Epoch 512 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1953.7861 - val_loss: 4657.7430\n",
      "Epoch 513 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1901.0989 - val_loss: 4821.8015\n",
      "Epoch 514 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2019.3970 - val_loss: 4822.6482\n",
      "Epoch 515 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1789.5228 - val_loss: 4493.9527\n",
      "Epoch 516 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2461.8782 - val_loss: 4768.0909\n",
      "Epoch 517 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1715.8751 - val_loss: 4574.1420\n",
      "Epoch 518 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2343.1320 - val_loss: 4858.5488\n",
      "Epoch 519 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1763.4631 - val_loss: 4454.4262\n",
      "Epoch 520 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2118.5033 - val_loss: 4858.0906\n",
      "Epoch 521 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1622.9008 - val_loss: 4366.6616\n",
      "Epoch 522 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1944.3316 - val_loss: 4596.2924\n",
      "Epoch 523 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1772.3608 - val_loss: 4117.6681\n",
      "Epoch 524 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2042.0825 - val_loss: 4335.4064\n",
      "Epoch 525 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1684.6325 - val_loss: 4118.2085\n",
      "Epoch 526 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1873.9915 - val_loss: 4242.7995\n",
      "Epoch 527 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1231.0992 - val_loss: 4168.2219\n",
      "Epoch 528 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1378.7863 - val_loss: 4350.6307\n",
      "Epoch 529 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2823.1086 - val_loss: 4381.6902\n",
      "Epoch 530 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1965.6097 - val_loss: 4507.8155\n",
      "Epoch 531 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2170.7822 - val_loss: 4404.3757\n",
      "Epoch 532 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1930.6854 - val_loss: 4514.1885\n",
      "Epoch 533 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1826.6909 - val_loss: 4469.0456\n",
      "Epoch 534 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2031.1292 - val_loss: 4389.0213\n",
      "Epoch 535 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2000.0087 - val_loss: 4421.4457\n",
      "Epoch 536 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2038.1240 - val_loss: 4390.1772\n",
      "Epoch 537 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2066.7252 - val_loss: 4461.6417\n",
      "Epoch 538 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1985.8294 - val_loss: 4307.3291\n",
      "Epoch 539 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1860.5286 - val_loss: 4495.1288\n",
      "Epoch 540 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2053.2925 - val_loss: 4197.1923\n",
      "Epoch 541 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1927.1337 - val_loss: 4278.1766\n",
      "Epoch 542 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1990.4022 - val_loss: 4250.8074\n",
      "Epoch 543 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1868.1034 - val_loss: 4096.5340\n",
      "Epoch 544 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2007.2121 - val_loss: 4141.5183\n",
      "Epoch 545 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2520.4186 - val_loss: 4008.0738\n",
      "Epoch 546 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3054.4499 - val_loss: 3839.6942\n",
      "Epoch 547 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2618.8374 - val_loss: 3856.2224\n",
      "Epoch 548 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2499.8521 - val_loss: 4145.1564\n",
      "Epoch 549 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2389.0155 - val_loss: 4198.8894\n",
      "Epoch 550 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2154.9369 - val_loss: 4156.9865\n",
      "Epoch 551 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2193.9053 - val_loss: 3976.1452\n",
      "Epoch 552 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2069.2226 - val_loss: 3941.3993\n",
      "Epoch 553 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2314.6870 - val_loss: 3977.3777\n",
      "Epoch 554 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2213.0839 - val_loss: 4255.4474\n",
      "Epoch 555 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2006.8585 - val_loss: 3888.5418\n",
      "Epoch 556 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2073.5393 - val_loss: 3978.4821\n",
      "Epoch 557 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2021.2561 - val_loss: 3808.7838\n",
      "Epoch 558 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2090.2515 - val_loss: 3861.8519\n",
      "Epoch 559 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2416.7612 - val_loss: 3796.3886\n",
      "Epoch 560 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2433.0261 - val_loss: 4099.4949\n",
      "Epoch 561 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2322.1175 - val_loss: 3760.2090\n",
      "Epoch 562 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2057.7767 - val_loss: 3987.8850\n",
      "Epoch 563 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2189.6313 - val_loss: 4222.8406\n",
      "Epoch 564 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1935.5998 - val_loss: 4062.2057\n",
      "Epoch 565 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2155.6652 - val_loss: 3584.2362\n",
      "Epoch 566 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2237.0261 - val_loss: 3843.6904\n",
      "Epoch 567 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1959.6615 - val_loss: 3617.8857\n",
      "Epoch 568 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2217.6245 - val_loss: 3799.7772\n",
      "Epoch 569 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1960.3596 - val_loss: 3784.9372\n",
      "Epoch 570 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2365.9514 - val_loss: 3861.9476\n",
      "Epoch 571 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1886.5974 - val_loss: 4181.9801\n",
      "Epoch 572 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2035.3010 - val_loss: 3702.4721\n",
      "Epoch 573 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2238.2776 - val_loss: 3999.5894\n",
      "Epoch 574 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1839.0568 - val_loss: 3623.9985\n",
      "Epoch 575 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2533.4704 - val_loss: 3997.4576\n",
      "Epoch 576 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2116.2713 - val_loss: 4397.1099\n",
      "Epoch 577 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1900.9369 - val_loss: 3982.9140\n",
      "Epoch 578 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2174.7910 - val_loss: 3877.0156\n",
      "Epoch 579 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2004.2815 - val_loss: 3874.2026\n",
      "Epoch 580 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2519.7753 - val_loss: 4047.9255\n",
      "Epoch 581 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2358.7706 - val_loss: 3983.6322\n",
      "Epoch 582 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2289.5608 - val_loss: 4137.5235\n",
      "Epoch 583 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2307.7753 - val_loss: 3772.1510\n",
      "Epoch 584 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2581.8431 - val_loss: 3948.5574\n",
      "Epoch 585 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1941.1305 - val_loss: 3673.7023\n",
      "Epoch 586 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1978.1973 - val_loss: 3493.7320\n",
      "Epoch 587 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2203.7484 - val_loss: 3675.7905\n",
      "Epoch 588 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2077.9851 - val_loss: 3426.5455\n",
      "Epoch 589 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2457.4632 - val_loss: 3658.5641\n",
      "Epoch 590 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2209.9742 - val_loss: 3306.3773\n",
      "Epoch 591 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2751.0423 - val_loss: 3593.7048\n",
      "Epoch 592 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2024.4569 - val_loss: 3774.7493\n",
      "Epoch 593 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1998.1574 - val_loss: 3498.7538\n",
      "Epoch 594 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2189.8742 - val_loss: 3556.7559\n",
      "Epoch 595 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4983.8507 - val_loss: 3250.3814\n",
      "Epoch 596 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2511.0004 - val_loss: 3246.6764\n",
      "Epoch 597 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2240.5715 - val_loss: 3290.8150\n",
      "Epoch 598 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2372.5778 - val_loss: 3405.2738\n",
      "Epoch 599 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2178.9458 - val_loss: 3386.5228\n",
      "Epoch 600 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2319.8292 - val_loss: 3409.5040\n",
      "Epoch 601 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2169.0739 - val_loss: 3459.4141\n",
      "Epoch 602 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2123.8654 - val_loss: 3485.0905\n",
      "Epoch 603 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2181.9366 - val_loss: 3521.5015\n",
      "Epoch 604 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2459.6537 - val_loss: 3626.4012\n",
      "Epoch 605 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2364.1118 - val_loss: 3923.7816\n",
      "Epoch 606 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1961.8157 - val_loss: 3402.1180\n",
      "Epoch 607 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2232.5054 - val_loss: 3597.4991\n",
      "Epoch 608 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2340.3115 - val_loss: 3560.9953\n",
      "Epoch 609 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2125.9685 - val_loss: 3419.7193\n",
      "Epoch 610 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2773.9344 - val_loss: 3558.3132\n",
      "Epoch 611 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2292.8019 - val_loss: 3400.5114\n",
      "Epoch 612 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2302.1719 - val_loss: 3620.0718\n",
      "Epoch 613 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2193.8521 - val_loss: 3333.3290\n",
      "Epoch 614 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3155.1437 - val_loss: 3612.9484\n",
      "Epoch 615 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2827.2544 - val_loss: 3698.9586\n",
      "Epoch 616 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2768.8302 - val_loss: 4123.8999\n",
      "Epoch 617 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2855.7496 - val_loss: 4019.9739\n",
      "Epoch 618 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2733.7098 - val_loss: 4338.0199\n",
      "Epoch 619 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2953.3580 - val_loss: 4206.7596\n",
      "Epoch 620 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2179.4939 - val_loss: 4443.6479\n",
      "Epoch 621 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2644.5793 - val_loss: 3889.3280\n",
      "Epoch 622 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2973.4878 - val_loss: 4653.5135\n",
      "Epoch 623 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2378.7496 - val_loss: 3989.9345\n",
      "Epoch 624 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3084.2703 - val_loss: 4758.7641\n",
      "Epoch 625 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2353.7503 - val_loss: 3897.0685\n",
      "Epoch 626 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3650.4570 - val_loss: 5372.2710\n",
      "Epoch 627 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2409.6923 - val_loss: 3911.2777\n",
      "Epoch 628 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3603.9889 - val_loss: 5573.7969\n",
      "Epoch 629 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2338.0629 - val_loss: 3734.9559\n",
      "Epoch 630 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4148.5749 - val_loss: 4979.0342\n",
      "Epoch 631 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2626.1504 - val_loss: 4021.4866\n",
      "Epoch 632 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3404.1193 - val_loss: 4561.7251\n",
      "Epoch 633 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2593.7908 - val_loss: 4032.5589\n",
      "Epoch 634 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2952.1604 - val_loss: 4486.4905\n",
      "Epoch 635 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2418.7797 - val_loss: 3782.8679\n",
      "Epoch 636 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2850.0780 - val_loss: 3884.8699\n",
      "Epoch 637 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3143.6980 - val_loss: 4377.9703\n",
      "Epoch 638 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2360.9606 - val_loss: 3658.6789\n",
      "Epoch 639 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2090.7237 - val_loss: 3519.2301\n",
      "Epoch 640 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2696.7543 - val_loss: 3469.1514\n",
      "Epoch 641 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2611.0532 - val_loss: 3553.8617\n",
      "Epoch 642 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2685.9168 - val_loss: 3490.4206\n",
      "Epoch 643 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2315.6558 - val_loss: 3633.7507\n",
      "Epoch 644 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1866.4662 - val_loss: 3199.1250\n",
      "Epoch 645 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1984.5046 - val_loss: 3171.2815\n",
      "Epoch 646 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1721.4096 - val_loss: 3091.9284\n",
      "Epoch 647 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2057.4746 - val_loss: 3166.7778\n",
      "Epoch 648 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1804.6805 - val_loss: 3128.8667\n",
      "Epoch 649 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2259.6118 - val_loss: 3268.0251\n",
      "Epoch 650 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1684.9257 - val_loss: 3081.5776\n",
      "Epoch 651 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2296.6941 - val_loss: 3075.30862\n",
      "Epoch 652 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2167.4678 - val_loss: 3191.0782\n",
      "Epoch 653 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1841.7494 - val_loss: 3015.1895\n",
      "Epoch 654 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2109.3830 - val_loss: 3165.0434\n",
      "Epoch 655 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1978.9894 - val_loss: 3153.9168\n",
      "Epoch 656 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1754.7276 - val_loss: 3109.0160\n",
      "Epoch 657 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2082.2360 - val_loss: 3176.0836\n",
      "Epoch 658 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1800.7330 - val_loss: 3044.7751\n",
      "Epoch 659 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1867.5020 - val_loss: 3123.8703\n",
      "Epoch 660 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2044.5443 - val_loss: 3020.1601\n",
      "Epoch 661 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1800.7152 - val_loss: 3155.8136167\n",
      "Epoch 662 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1747.9300 - val_loss: 3146.3606\n",
      "Epoch 663 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1548.9692 - val_loss: 3084.3509\n",
      "Epoch 664 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1821.5099 - val_loss: 3253.0726\n",
      "Epoch 665 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1368.6896 - val_loss: 3187.8503\n",
      "Epoch 666 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1296.3435 - val_loss: 2916.3213\n",
      "Epoch 667 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1353.8997 - val_loss: 3056.1483\n",
      "Epoch 668 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1165.3460 - val_loss: 2430.0557\n",
      "Epoch 669 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2671.2072 - val_loss: 2920.5765\n",
      "Epoch 670 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4245.4131 - val_loss: 3880.7732\n",
      "Epoch 671 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1925.4845 - val_loss: 3280.2349\n",
      "Epoch 672 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3514.0322 - val_loss: 3595.1353\n",
      "Epoch 673 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2237.7062 - val_loss: 3293.7382\n",
      "Epoch 674 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3270.3909 - val_loss: 3603.7357\n",
      "Epoch 675 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1966.6049 - val_loss: 3290.7763\n",
      "Epoch 676 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2872.5653 - val_loss: 3397.8004\n",
      "Epoch 677 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2884.8569 - val_loss: 3311.0840\n",
      "Epoch 678 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2159.4479 - val_loss: 3247.8341\n",
      "Epoch 679 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2492.8576 - val_loss: 3254.3227\n",
      "Epoch 680 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3196.3118 - val_loss: 3375.1733\n",
      "Epoch 681 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2309.2742 - val_loss: 3295.0300\n",
      "Epoch 682 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2084.0241 - val_loss: 3167.4714\n",
      "Epoch 683 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3043.0863 - val_loss: 3593.6559\n",
      "Epoch 684 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2675.2097 - val_loss: 3415.2541\n",
      "Epoch 685 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1986.1819 - val_loss: 3042.8055\n",
      "Epoch 686 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2842.9742 - val_loss: 3205.7351\n",
      "Epoch 687 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2159.3817 - val_loss: 3146.9124\n",
      "Epoch 688 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2221.1147 - val_loss: 2881.2222\n",
      "Epoch 689 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1913.5842 - val_loss: 3059.3067\n",
      "Epoch 690 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2469.8091 - val_loss: 3108.2537\n",
      "Epoch 691 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2875.8749 - val_loss: 3286.2455\n",
      "Epoch 692 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1841.8885 - val_loss: 3198.0668\n",
      "Epoch 693 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2679.1097 - val_loss: 3405.3251\n",
      "Epoch 694 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2860.6288 - val_loss: 3397.2913\n",
      "Epoch 695 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1973.8539 - val_loss: 3315.8206\n",
      "Epoch 696 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2649.0683 - val_loss: 3339.1650\n",
      "Epoch 697 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2802.1355 - val_loss: 3371.8083\n",
      "Epoch 698 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1926.1691 - val_loss: 3403.7522\n",
      "Epoch 699 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2128.6952 - val_loss: 3409.3932\n",
      "Epoch 700 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1728.7174 - val_loss: 3252.7121\n",
      "Epoch 701 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2891.0085 - val_loss: 3134.6676\n",
      "Epoch 702 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3081.3962 - val_loss: 3242.6956\n",
      "Epoch 703 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2541.1907 - val_loss: 2947.8490\n",
      "Epoch 704 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2577.3496 - val_loss: 2944.5925\n",
      "Epoch 705 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2510.1724 - val_loss: 2947.8179\n",
      "Epoch 706 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2052.5422 - val_loss: 2934.9146\n",
      "Epoch 707 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2980.6535 - val_loss: 3156.5074\n",
      "Epoch 708 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2406.5669 - val_loss: 2959.8970\n",
      "Epoch 709 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2098.5615 - val_loss: 2999.7422\n",
      "Epoch 710 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2033.7517 - val_loss: 2933.7933\n",
      "Epoch 711 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2173.9197 - val_loss: 2901.4007\n",
      "Epoch 712 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1918.0946 - val_loss: 2957.3550\n",
      "Epoch 713 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2446.2160 - val_loss: 2992.0681\n",
      "Epoch 714 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3351.5600 - val_loss: 3336.3846\n",
      "Epoch 715 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1772.4246 - val_loss: 3126.7034\n",
      "Epoch 716 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2580.1940 - val_loss: 2891.1568\n",
      "Epoch 717 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2572.2233 - val_loss: 3015.3244\n",
      "Epoch 718 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1846.9021 - val_loss: 2961.8268\n",
      "Epoch 719 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2196.6869 - val_loss: 2891.5912\n",
      "Epoch 720 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2298.0575 - val_loss: 2897.5896\n",
      "Epoch 721 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2289.2692 - val_loss: 2933.4411\n",
      "Epoch 722 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2105.6881 - val_loss: 2751.4980\n",
      "Epoch 723 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2582.5988 - val_loss: 2910.5398\n",
      "Epoch 724 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1914.1546 - val_loss: 3107.5250\n",
      "Epoch 725 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2053.4223 - val_loss: 2843.1563\n",
      "Epoch 726 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2744.8286 - val_loss: 3038.8979\n",
      "Epoch 727 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1910.3202 - val_loss: 3100.0494\n",
      "Epoch 728 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2303.9497 - val_loss: 3065.0050\n",
      "Epoch 729 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2517.4731 - val_loss: 2930.4062\n",
      "Epoch 730 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2374.0427 - val_loss: 3070.0444\n",
      "Epoch 731 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1859.8278 - val_loss: 2885.1299\n",
      "Epoch 732 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2727.3532 - val_loss: 2951.6603\n",
      "Epoch 733 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2338.1622 - val_loss: 3098.7184\n",
      "Epoch 734 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1742.4608 - val_loss: 2909.4429\n",
      "Epoch 735 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2448.1550 - val_loss: 2958.7798\n",
      "Epoch 736 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1820.1434 - val_loss: 3003.3249\n",
      "Epoch 737 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2295.2338 - val_loss: 2724.4493\n",
      "Epoch 738 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2700.7731 - val_loss: 2943.7331\n",
      "Epoch 739 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2325.4806 - val_loss: 2780.4244\n",
      "Epoch 740 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2033.9975 - val_loss: 2857.7753\n",
      "Epoch 741 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2911.8307 - val_loss: 2849.9998\n",
      "Epoch 742 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2094.1620 - val_loss: 2763.3784\n",
      "Epoch 743 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1910.9207 - val_loss: 2614.7876\n",
      "Epoch 744 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2263.8309 - val_loss: 2814.0988\n",
      "Epoch 745 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1821.9374 - val_loss: 2704.3701\n",
      "Epoch 746 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2648.2288 - val_loss: 2791.9983\n",
      "Epoch 747 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1832.7280 - val_loss: 2480.6298\n",
      "Epoch 748 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2237.3524 - val_loss: 2633.9797\n",
      "Epoch 749 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1917.3353 - val_loss: 2673.1428\n",
      "Epoch 750 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1960.5601 - val_loss: 2691.5851\n",
      "Epoch 751 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1731.3983 - val_loss: 2659.5860\n",
      "Epoch 752 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3400.4425 - val_loss: 3601.1974\n",
      "Epoch 753 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1994.4518 - val_loss: 2703.9531\n",
      "Epoch 754 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1786.6641 - val_loss: 2697.0387\n",
      "Epoch 755 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2444.2028 - val_loss: 2659.4407\n",
      "Epoch 756 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2371.5120 - val_loss: 2625.9907\n",
      "Epoch 757 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2323.9102 - val_loss: 2650.0425\n",
      "Epoch 758 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2271.8423 - val_loss: 2682.4146\n",
      "Epoch 759 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2512.0811 - val_loss: 2640.2058\n",
      "Epoch 760 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2183.0577 - val_loss: 2699.2117\n",
      "Epoch 761 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2578.9677 - val_loss: 2672.3464\n",
      "Epoch 762 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2327.2046 - val_loss: 2748.8735\n",
      "Epoch 763 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2610.5205 - val_loss: 2698.7109\n",
      "Epoch 764 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2212.9233 - val_loss: 2771.6665\n",
      "Epoch 765 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2292.2363 - val_loss: 2668.7616\n",
      "Epoch 766 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2296.3065 - val_loss: 2683.2310\n",
      "Epoch 767 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2078.4787 - val_loss: 2712.2893\n",
      "Epoch 768 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2137.2922 - val_loss: 2669.4517\n",
      "Epoch 769 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1974.7253 - val_loss: 2752.7501\n",
      "Epoch 770 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1649.1941 - val_loss: 2693.6406\n",
      "Epoch 771 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1341.8486 - val_loss: 2736.4416\n",
      "Epoch 772 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3527.7798 - val_loss: 2846.0822\n",
      "Epoch 773 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2601.6932 - val_loss: 2839.5300\n",
      "Epoch 774 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2154.9140 - val_loss: 2631.4981\n",
      "Epoch 775 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2404.2758 - val_loss: 2718.5671\n",
      "Epoch 776 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1967.3257 - val_loss: 2686.0045\n",
      "Epoch 777 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2199.7958 - val_loss: 2663.8645\n",
      "Epoch 778 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2009.9201 - val_loss: 2660.4022\n",
      "Epoch 779 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3208.6499 - val_loss: 2864.4768\n",
      "Epoch 780 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1537.3205 - val_loss: 2847.2434\n",
      "Epoch 781 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2190.7427 - val_loss: 2687.3382\n",
      "Epoch 782 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3528.8018 - val_loss: 3046.2877\n",
      "Epoch 783 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2433.3300 - val_loss: 3185.0790\n",
      "Epoch 784 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1939.4277 - val_loss: 2781.6921\n",
      "Epoch 785 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2820.9549 - val_loss: 2777.7565\n",
      "Epoch 786 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2654.9725 - val_loss: 2785.9305\n",
      "Epoch 787 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2561.4002 - val_loss: 2774.5690\n",
      "Epoch 788 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2557.6318 - val_loss: 2787.4279\n",
      "Epoch 789 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2685.5289 - val_loss: 2683.8556\n",
      "Epoch 790 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2781.5875 - val_loss: 2757.6845\n",
      "Epoch 791 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2674.1080 - val_loss: 2761.5927\n",
      "Epoch 792 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2929.4592 - val_loss: 2867.4105\n",
      "Epoch 793 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2956.8916 - val_loss: 2805.1613\n",
      "Epoch 794 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2809.1260 - val_loss: 2767.0869\n",
      "Epoch 795 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2485.7748 - val_loss: 2802.3291\n",
      "Epoch 796 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3030.6522 - val_loss: 3012.4276\n",
      "Epoch 797 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2602.5043 - val_loss: 2895.6386\n",
      "Epoch 798 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2664.2241 - val_loss: 2860.9952\n",
      "Epoch 799 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2988.2884 - val_loss: 2892.0207\n",
      "Epoch 800 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1972.5138 - val_loss: 2735.0329\n",
      "Epoch 801 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3581.0033 - val_loss: 2776.7512\n",
      "Epoch 802 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2509.6308 - val_loss: 2729.7878\n",
      "Epoch 803 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2682.6013 - val_loss: 2728.0590\n",
      "Epoch 804 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2598.1323 - val_loss: 2699.2061\n",
      "Epoch 805 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2611.5091 - val_loss: 2695.0501\n",
      "Epoch 806 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2553.3960 - val_loss: 2705.7802\n",
      "Epoch 807 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2498.5021 - val_loss: 2701.3975\n",
      "Epoch 808 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2521.5235 - val_loss: 2697.2735\n",
      "Epoch 809 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2485.0064 - val_loss: 2682.8469\n",
      "Epoch 810 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2507.0783 - val_loss: 2695.9921\n",
      "Epoch 811 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2400.5098 - val_loss: 2681.5352\n",
      "Epoch 812 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2544.0506 - val_loss: 2703.1689\n",
      "Epoch 813 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2401.5285 - val_loss: 2698.4063\n",
      "Epoch 814 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2588.1669 - val_loss: 2678.9563\n",
      "Epoch 815 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2520.5003 - val_loss: 2675.5706\n",
      "Epoch 816 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2402.8238 - val_loss: 2683.3434\n",
      "Epoch 817 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2502.7775 - val_loss: 2665.8743\n",
      "Epoch 818 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2452.1500 - val_loss: 2685.0644\n",
      "Epoch 819 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2496.8049 - val_loss: 2702.8848\n",
      "Epoch 820 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2883.8514 - val_loss: 2774.3183\n",
      "Epoch 821 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2732.2992 - val_loss: 2766.2622\n",
      "Epoch 822 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2683.5854 - val_loss: 2790.4805\n",
      "Epoch 823 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2680.4934 - val_loss: 2764.0660\n",
      "Epoch 824 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2648.3701 - val_loss: 2763.2168\n",
      "Epoch 825 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2436.0140 - val_loss: 2869.3144\n",
      "Epoch 826 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3470.7603 - val_loss: 2700.8114\n",
      "Epoch 827 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2478.0267 - val_loss: 2661.6054\n",
      "Epoch 828 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2471.6711 - val_loss: 2816.3467\n",
      "Epoch 829 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4122.4952 - val_loss: 2989.4279\n",
      "Epoch 830 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2851.5438 - val_loss: 3152.3960\n",
      "Epoch 831 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2646.5344 - val_loss: 2928.6228\n",
      "Epoch 832 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2856.0706 - val_loss: 2910.0580\n",
      "Epoch 833 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3051.8208 - val_loss: 3522.7816\n",
      "Epoch 834 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1887.9055 - val_loss: 3020.7957\n",
      "Epoch 835 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2495.1398 - val_loss: 2689.6886\n",
      "Epoch 836 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3131.5156 - val_loss: 3193.5180\n",
      "Epoch 837 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1690.1109 - val_loss: 2822.6148\n",
      "Epoch 838 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2331.2545 - val_loss: 2761.9864\n",
      "Epoch 839 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3554.1033 - val_loss: 3435.9394\n",
      "Epoch 840 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1520.5646 - val_loss: 2827.3232\n",
      "Epoch 841 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2146.0021 - val_loss: 2837.3372\n",
      "Epoch 842 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2814.7309 - val_loss: 3024.4918\n",
      "Epoch 843 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1658.7271 - val_loss: 2924.7585\n",
      "Epoch 844 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1750.6594 - val_loss: 2847.8905\n",
      "Epoch 845 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3046.8607 - val_loss: 3144.9036\n",
      "Epoch 846 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1506.2379 - val_loss: 2867.4133\n",
      "Epoch 847 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 1817.9995 - val_loss: 2835.5009\n",
      "Epoch 848 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2888.4143 - val_loss: 3049.2891\n",
      "Epoch 849 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1477.7666 - val_loss: 2792.2670\n",
      "Epoch 850 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1820.6628 - val_loss: 2820.3005\n",
      "Epoch 851 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3023.3377 - val_loss: 2970.2412\n",
      "Epoch 852 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1349.3127 - val_loss: 2798.7602\n",
      "Epoch 853 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1782.6719 - val_loss: 2805.6584\n",
      "Epoch 854 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3263.9782 - val_loss: 3116.9500\n",
      "Epoch 855 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1284.0361 - val_loss: 2763.0438\n",
      "Epoch 856 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1611.1189 - val_loss: 2789.8147\n",
      "Epoch 857 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3528.0979 - val_loss: 3268.8628\n",
      "Epoch 858 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1302.7648 - val_loss: 2743.5868\n",
      "Epoch 859 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1493.4570 - val_loss: 2783.5649\n",
      "Epoch 860 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - ETA: 0s - loss: 3375.27 - 0s - loss: 3288.5333 - val_loss: 3053.4320\n",
      "Epoch 861 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1343.5396 - val_loss: 2789.0645\n",
      "Epoch 862 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1497.2596 - val_loss: 2788.9172\n",
      "Epoch 863 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1277.3636 - val_loss: 2213.1288\n",
      "Epoch 864 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1373.7962 - val_loss: 2433.9968\n",
      "Epoch 865 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1974.9088 - val_loss: 2564.1014\n",
      "Epoch 866 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2003.9420 - val_loss: 2756.2494\n",
      "Epoch 867 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1677.6220 - val_loss: 2709.7315\n",
      "Epoch 868 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2986.4770 - val_loss: 2695.1961\n",
      "Epoch 869 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1623.9399 - val_loss: 2572.4238\n",
      "Epoch 870 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1500.2781 - val_loss: 2669.5096\n",
      "Epoch 871 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3090.5274 - val_loss: 2560.8868\n",
      "Epoch 872 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1999.8661 - val_loss: 2826.7977\n",
      "Epoch 873 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2043.8768 - val_loss: 2940.0824\n",
      "Epoch 874 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1166.7693 - val_loss: 2405.1991\n",
      "Epoch 875 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2004.5583 - val_loss: 2811.5262\n",
      "Epoch 876 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3642.1819 - val_loss: 2636.9302\n",
      "Epoch 877 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1572.4065 - val_loss: 2860.6982\n",
      "Epoch 878 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1524.6474 - val_loss: 2520.8186\n",
      "Epoch 879 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1654.5033 - val_loss: 2310.0871\n",
      "Epoch 880 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1819.0275 - val_loss: 2727.0219\n",
      "Epoch 881 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3235.7919 - val_loss: 2598.6357\n",
      "Epoch 882 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1795.9121 - val_loss: 2523.1231\n",
      "Epoch 883 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1601.2226 - val_loss: 2659.5073\n",
      "Epoch 884 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4122.0823 - val_loss: 2704.1621\n",
      "Epoch 885 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1815.5029 - val_loss: 2672.8526\n",
      "Epoch 886 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2691.7561 - val_loss: 2792.5617\n",
      "Epoch 887 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2012.4194 - val_loss: 2807.5619\n",
      "Epoch 888 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1377.0219 - val_loss: 2725.0708\n",
      "Epoch 889 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1981.1447 - val_loss: 2739.5715\n",
      "Epoch 890 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2051.6239 - val_loss: 2596.0376\n",
      "Epoch 891 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2029.5772 - val_loss: 2745.4574\n",
      "Epoch 892 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3401.1130 - val_loss: 2830.2060\n",
      "Epoch 893 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2696.3193 - val_loss: 2868.9311\n",
      "Epoch 894 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2698.2587 - val_loss: 2874.1360\n",
      "Epoch 895 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2608.2775 - val_loss: 2815.4751\n",
      "Epoch 896 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2404.1515 - val_loss: 2763.4267\n",
      "Epoch 897 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3542.8451 - val_loss: 3020.4852\n",
      "Epoch 898 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2997.5182 - val_loss: 2892.9900\n",
      "Epoch 899 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2259.9970 - val_loss: 2784.3881\n",
      "Epoch 900 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 2035.6888 - val_loss: 2754.5705\n",
      "Epoch 901 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4375.8894 - val_loss: 3269.1362\n",
      "Epoch 902 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2804.3602 - val_loss: 3009.6729\n",
      "Epoch 903 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2530.9644 - val_loss: 3078.4219\n",
      "Epoch 904 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1957.4795 - val_loss: 2820.0449\n",
      "Epoch 905 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2164.1685 - val_loss: 2659.3364\n",
      "Epoch 906 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3951.0964 - val_loss: 3101.5617\n",
      "Epoch 907 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2475.4303 - val_loss: 2781.1906\n",
      "Epoch 908 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2059.6527 - val_loss: 2671.3554\n",
      "Epoch 909 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2153.7994 - val_loss: 2666.4837\n",
      "Epoch 910 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2838.3870 - val_loss: 2884.3378\n",
      "Epoch 911 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2496.8613 - val_loss: 2801.6317\n",
      "Epoch 912 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1886.2551 - val_loss: 2732.5716\n",
      "Epoch 913 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 4074.6241 - val_loss: 2838.7061\n",
      "Epoch 914 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2792.5298 - val_loss: 2695.5694\n",
      "Epoch 915 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2358.1683 - val_loss: 2735.1407\n",
      "Epoch 916 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2278.8148 - val_loss: 2765.1579\n",
      "Epoch 917 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2070.9247 - val_loss: 2682.4670\n",
      "Epoch 918 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3662.6323 - val_loss: 2878.5570\n",
      "Epoch 919 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2854.7596 - val_loss: 2775.3263\n",
      "Epoch 920 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2374.0533 - val_loss: 2646.8898\n",
      "Epoch 921 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2062.9812 - val_loss: 2695.2831\n",
      "Epoch 922 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1925.9261 - val_loss: 2704.7187\n",
      "Epoch 923 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2724.1776 - val_loss: 2539.8407\n",
      "Epoch 924 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2674.2654 - val_loss: 2631.0000\n",
      "Epoch 925 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2427.5563 - val_loss: 2601.2117\n",
      "Epoch 926 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2361.2028 - val_loss: 2590.0617\n",
      "Epoch 927 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2341.2528 - val_loss: 2599.4901\n",
      "Epoch 928 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2223.6512 - val_loss: 2656.4403\n",
      "Epoch 929 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2070.8280 - val_loss: 2557.5120\n",
      "Epoch 930 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2019.4495 - val_loss: 2694.3467\n",
      "Epoch 931 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3225.7117 - val_loss: 2812.9941\n",
      "Epoch 932 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2870.1186 - val_loss: 2890.1491\n",
      "Epoch 933 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2447.6158 - val_loss: 2653.8889\n",
      "Epoch 934 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2318.8379 - val_loss: 2701.2681\n",
      "Epoch 935 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2186.6843 - val_loss: 2649.4560\n",
      "Epoch 936 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2061.0391 - val_loss: 2612.8419\n",
      "Epoch 937 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1973.7728 - val_loss: 2640.4330\n",
      "Epoch 938 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2184.0107 - val_loss: 2644.3401\n",
      "Epoch 939 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3070.5940 - val_loss: 2912.7556\n",
      "Epoch 940 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2195.1850 - val_loss: 2708.8370\n",
      "Epoch 941 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2208.5931 - val_loss: 2729.6581\n",
      "Epoch 942 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1949.4868 - val_loss: 2632.1945\n",
      "Epoch 943 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1971.3424 - val_loss: 2670.3782\n",
      "Epoch 944 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1767.8879 - val_loss: 2623.4062\n",
      "Epoch 945 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1592.5811 - val_loss: 2610.8064\n",
      "Epoch 946 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1669.3217 - val_loss: 2893.1644\n",
      "Epoch 947 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2179.0727 - val_loss: 2733.2505\n",
      "Epoch 948 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2172.4110 - val_loss: 2684.7005\n",
      "Epoch 949 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1587.0057 - val_loss: 2578.4825\n",
      "Epoch 950 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1533.5162 - val_loss: 2553.5345\n",
      "Epoch 951 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1570.8345 - val_loss: 2705.2990\n",
      "Epoch 952 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1459.8343 - val_loss: 2804.1506\n",
      "Epoch 953 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 1264.9356 - val_loss: 2662.9843\n",
      "Epoch 954 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2394.5388 - val_loss: 2828.0982\n",
      "Epoch 955 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2280.9049 - val_loss: 2626.0051\n",
      "Epoch 956 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2937.1814 - val_loss: 3004.2828\n",
      "Epoch 957 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1974.5419 - val_loss: 2729.9515\n",
      "Epoch 958 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1757.8263 - val_loss: 2613.5471\n",
      "Epoch 959 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1883.0269 - val_loss: 2622.7693\n",
      "Epoch 960 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2017.4615 - val_loss: 2711.4590\n",
      "Epoch 961 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1671.9149 - val_loss: 2567.3674\n",
      "Epoch 962 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1540.1963 - val_loss: 2636.6753\n",
      "Epoch 963 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1734.1122 - val_loss: 2953.7880\n",
      "Epoch 964 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3183.5647 - val_loss: 3077.8535\n",
      "Epoch 965 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1738.1828 - val_loss: 2614.1641\n",
      "Epoch 966 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1312.4808 - val_loss: 2575.4401\n",
      "Epoch 967 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1575.3409 - val_loss: 2533.3850\n",
      "Epoch 968 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1413.8132 - val_loss: 2570.1399\n",
      "Epoch 969 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1525.3835 - val_loss: 2958.2867\n",
      "Epoch 970 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1705.9984 - val_loss: 2815.3776\n",
      "Epoch 971 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1222.7418 - val_loss: 2608.3024\n",
      "Epoch 972 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1553.4638 - val_loss: 2763.9548\n",
      "Epoch 973 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2462.8544 - val_loss: 2393.6147\n",
      "Epoch 974 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1756.1770 - val_loss: 2780.8409\n",
      "Epoch 975 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1134.9514 - val_loss: 2573.1107\n",
      "Epoch 976 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1269.1557 - val_loss: 2443.9662\n",
      "Epoch 977 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1308.0165 - val_loss: 2414.1036\n",
      "Epoch 978 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1482.3718 - val_loss: 2473.6621\n",
      "Epoch 979 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1805.6973 - val_loss: 2769.5421\n",
      "Epoch 980 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1421.4594 - val_loss: 2604.1794\n",
      "Epoch 981 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1382.8682 - val_loss: 2701.6115\n",
      "Epoch 982 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 2118.2612 - val_loss: 2986.2971\n",
      "Epoch 983 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1246.0232 - val_loss: 2658.9860\n",
      "Epoch 984 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1472.6596 - val_loss: 2679.4961\n",
      "Epoch 985 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1718.8729 - val_loss: 2808.8652\n",
      "Epoch 986 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1840.4484 - val_loss: 2555.8431\n",
      "Epoch 987 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1658.3224 - val_loss: 2495.8133\n",
      "Epoch 988 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1126.3252 - val_loss: 2398.3018\n",
      "Epoch 989 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1155.9335 - val_loss: 2417.2204\n",
      "Epoch 990 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1187.2917 - val_loss: 2477.9257\n",
      "Epoch 991 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1299.2596 - val_loss: 2639.7547\n",
      "Epoch 992 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1459.1668 - val_loss: 2549.4394\n",
      "Epoch 993 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1395.5007 - val_loss: 2584.5995\n",
      "Epoch 994 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1701.6262 - val_loss: 2528.8520\n",
      "Epoch 995 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1102.3838 - val_loss: 2523.5228\n",
      "Epoch 996 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1258.1621 - val_loss: 2729.6161\n",
      "Epoch 997 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1265.3349 - val_loss: 2590.5391\n",
      "Epoch 998 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 1403.9001 - val_loss: 2806.0731\n",
      "Epoch 999 / 1000\n",
      "Train on 90 samples, validate on 5 samples\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s - loss: 3735.4070 - val_loss: 3110.1694\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34920dbdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "Plotting Results\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8lOXV+P/PlX3fF7IAAbKwJhACsrkAIqhUtO5a16qt\n2j72aVW07e/52tYudnGttVK11dYFRRS3Igq4gSBhh7AlkJB938iemev3x8xggIRMkpnMdt6vV16Z\nueeeyZUbcuaec5/rXEprjRBCCPfl5egBCCGEsC8J9EII4eYk0AshhJuTQC+EEG5OAr0QQrg5CfRC\nCOHmJNALIYSbk0AvhBBuTgK9EEK4OR9HDwAgJiZGp6SkOHoYQgjhUrZv316jtY7tbz+nCPQpKSnk\n5uY6ehhCCOFSlFJF1uwnqRshhHBzEuiFEMLNSaAXQgg35xQ5+t50dXVRUlJCe3u7o4fi8gICAkhO\nTsbX19fRQxFCOIDTBvqSkhJCQ0NJSUlBKeXo4bgsrTW1tbWUlJQwZswYRw9HCOEATpu6aW9vJzo6\nWoL8ECmliI6Olk9GQngwpw30gAR5G5HjKIRnc+pAL4QQ9lLX0smaXaUYje6/nKoEeidTWFjIa6+9\nNuDn3XrrraxatcoOIxLCPT3/RQH3vbGLh1bvweDmwV4CvZMZbKAXQgzM/tIm/H28eDO3hJ++uYtu\ng9HRQ7IbCfT9+M9//sPMmTOZOnUqP/jBDygqKiItLY2amhqMRiPnnnsu69ato7CwkPHjx3PjjTcy\nYcIErrrqKlpbWwHYvn07559/PtOnT2fx4sWUl5cDkJ+fz4UXXkhWVhbZ2dkUFBTw0EMP8eWXXzJ1\n6lSeeOIJDAYDDzzwADNmzCAzM5Pnn38eMFXT/OhHPyIjI4MLL7yQqqoqhx0jIVyN1pq88iYun5rE\nA4szWLOrjB+/vpPObvcM9k5bXtnTr97fT15Zk01fc2JiGP/vO5POus+BAwdYuXIlmzZtwtfXl3vu\nuYfPP/+c5cuXc/fddzNz5kwmTpzIRRddRGFhIYcOHeLFF19k7ty53H777fztb3/jvvvu48c//jFr\n1qwhNjaWlStX8otf/IKXXnqJG2+8kYceeogrrriC9vZ2jEYjf/jDH/jzn//MBx98AMCKFSsIDw9n\n27ZtdHR0MHfuXC666CJ27tzJoUOHyMvLo7KykokTJ3L77bfb9BgJ4a4qmtqpa+lkYmIYt8xJwd/H\ni0c/PEDXq9v56w3ZBPh6O3qINuUSgd5R1q9fz/bt25kxYwYAbW1txMXF8cgjj/DWW2/x97//nV27\ndp3cf+TIkcydOxeA733vezz99NMsWbKEffv2sWjRIgAMBgMJCQk0NzdTWlrKFVdcAZgmNfVm3bp1\n7Nmz52T+vbGxkSNHjvDFF19w/fXX4+3tTWJiIgsWLLDbcRDC3ewvNZ04TkoMA+COc8fi7+PF/7dm\nP3e+ksuKm3II9HOfYG9VoFdKRQAvAJMBDdwOHAJWAilAIXCN1rpemWr5ngIuAVqBW7XWO4YyyP7O\nvO1Fa80tt9zC73//+1O2t7a2UlJSAsCJEycIDQ0FzixjVEqhtWbSpEl8/fXXpzzW3Nxs9RieeeYZ\nFi9efMr2jz76aEC/ixDiW3nlTSgF4xPCTm67aXYK/j7eLF+9h9v+9Q0v3jKDYH/3OBe2Nkf/FLBW\naz0eyAIOAA8B67XWacB6832Ai4E089ddwHM2HfEwWrhwIatWrTqZ/66rq6OoqIjly5dz44038utf\n/5o777zz5P7Hjx8/GdBfe+015s2bR0ZGBtXV1Se3d3V1sX//fkJDQ0lOTubdd98FoKOjg9bWVkJD\nQ095E1i8eDHPPfccXV1dABw+fJiWlhbOO+88Vq5cicFgoLy8nI0bNw7LMRHCHewvayQlOpiQ0wL5\nNTNG8sQ1U9l6rI4XvzrmoNHZXr+BXikVDpwHvAigte7UWjcAy4CXzbu9DFxuvr0MeEWbbAEilFIJ\nNh/5MJg4cSKPPvooF110EZmZmSxatIjCwkK2bdt2Mtj7+fnxz3/+E4CMjAyeffZZJkyYQH19PXff\nfTd+fn6sWrWK5cuXk5WVxdSpU9m8eTMA//73v3n66afJzMxkzpw5VFRUkJmZibe3N1lZWTzxxBPc\ncccdTJw4kezsbCZPnswPfvADuru7ueKKK0hLS2PixIncfPPNzJ4925GHSgiXsr+siYmJYb0+dvm0\nJMbEBLO/rHGYR2U/Suuz148qpaYCK4A8TGfz24H7gFKtdYR5HwXUa60jlFIfAH/QWn9lfmw9sFxr\n3efKIjk5Ofr0hUcOHDjAhAkTBv2LDbfCwkKWLl3Kvn37HD2UXrna8RTCXhrbusj61ToeWJzBvfNT\ne93nh//ezuHKZjbcf8HwDm6AlFLbtdY5/e1nTerGB8gGntNaTwNa+DZNA4A2vVsMaMaBUuoupVSu\nUiq3urp6IE8VQohBs1TwTerjjB4gPT6EwtoW2rsMwzUsu7Im0JcAJVrrreb7qzAF/kpLSsb83VLI\nXQqM7PH8ZPO2U2itV2itc7TWObGx/S556PRSUlKc9mxeCPGtvHJLoA/vc5+0+FCMGgqqTwzXsOyq\n30Cvta4AipVSGeZNCzGlcd4DbjFvuwVYY779HnCzMpkFNGqty207bCGEGJz9ZY3EhvoTG+rf5z4Z\nI0yVdEcq3SPQW1s79GPgVaWUH3AUuA3Tm8SbSqnvA0XANeZ9P8JUWpmPqbzyNpuOWAghhiCvrOms\naRuAlOhgfLwUhyutK4N2dlYFeq31LqC3hP/CXvbVwL1DHJcQQthce5eB/KoTLJwQd9b9/Hy8GBMT\nzGE3OaOXXjdCCI9xpPIE3UbNxIS+8/MW6fGhbnNGL4F+GIWEhABQVlbGVVddddZ9n3zyyZNN0az1\n2WefsXTp0kGPTwh3Z6mN7y91A5AWH0JxfSttna5feSOBfogMhoH/J0hMTOy3d/xgAr0Q4uzyypsI\n8fdhVFRQv/tmxIeiNeRXuX76RgL9WfTVejglJYXly5eTnZ3NW2+9RUFBAUuWLGH69Omce+65HDx4\nEIBjx44xe/ZspkyZwi9/+ctTXnfy5MmA6Y3i/vvvZ/LkyWRmZvLMM8/w9NNPU1ZWxvz585k/fz5g\nam42e/ZssrOzufrqqzlxwvSfb+3atYwfP57s7GxWr149zEdICNeyv6yJCQmheHn1v7xmWryp8sYd\n0jeu0bHnvw9BxV7bvuaIKXDxH/rdrbfWwwDR0dHs2GHq1bZw4UL+/ve/k5aWxtatW7nnnnvYsGED\n9913H3fffTc333wzzz77bK+vv2LFCgoLC9m1axc+Pj7U1dURFRXF448/zsaNG4mJiaGmpoZHH32U\nTz/9lODgYB577DEef/xxHnzwQe688042bNhAamoq1157re2OjxBuxmDUHChv4pqckf3vDKREB+Hn\n7cXhKgn0bq+31sPAyaB64sQJNm/ezNVXX33yOR0dHQBs2rSJt99+G4CbbrqJ5cuXn/H6n376KT/8\n4Q/x8TH9U0RFRZ2xz5YtW8jLyzs5js7OTmbPns3BgwcZM2YMaWlpJ8e3YsUKm/zeQribotoWWjsN\nffa4OZ2PtxdjY4PdopbeNQK9FWfe9tJb62GA4OBgAIxGIxEREaf0pT/b8wdDa82iRYt4/fXXT9ne\n188UQpxpv7n1wcQE6wI9mNI3O4rq7TWkYSM5+n701nq4p7CwMMaMGcNbb70FmILy7t27AZg7dy5v\nvPEGAK+++mqvr79o0SKef/55uru7AVMrZOCUdsWzZs1i06ZN5OfnA9DS0sLhw4cZP348hYWFFBQU\nAJzxRiCE+Nb+siZ8vRXp5ty7NTLiQyhtaKOlo9uOI7M/CfT96K318OleffVVXnzxRbKyspg0aRJr\n1pi6QTz11FM8++yzTJkyhdLSM9r9AHDHHXcwatQoMjMzycrKOrkw+F133cWSJUuYP38+sbGx/Otf\n/+L6668nMzPzZNomICCAFStWcOmll5KdnU1c3NkngQjhyfLKm0iNC8XPx/qwZ7kge8TFK2/6bVM8\nHJy1TbGztx4eCGc4nkI4itaaGb/9lAsy4vjz1VlWP+9YTQvz//wZf7wq0+qLuMPJlm2KhRAuqLG1\ni1+8s5e/bjji6KE4XHVzBzUnOq2aKNXTqKgg/H28OOLiJZaucTHWQaT1sHBVn+ZV8vN39lLV3EFs\nqD8/WpDm6CE51GAuxAJ4eynGxYZwyMUrb5z6jN4Z0kruQI6j52ho7eSnK3dxxyu5RAX7cU1OMtXN\nHdS1dDp6aA5laX1gbWllTxkjQl3+jN5pA31AQAC1tbUSpIZIa01tbS0BAQGOHoqws0/yKln0xBe8\nt7uM/1mYxns/msfSzETAPWZ3DkVeeROjo4MIDfAd8HPT4kMob2ynqb3LDiMbHk6buklOTqakpARZ\nZnDoAgICSE5OdvQwhJ0YjJoHVu1m9Y5Sxo8I5Z+3zmBykqk7o2UBjcOVzcwaG+3IYTrU/rKmAadt\nLNLjvl2EZProSFsOa9g4baD39fVlzJgxjh6GEE5vy9FaVu8o5Y55Y3hwyfhTygfjQv0JD/TlUIXn\nntE3tXdRVNvK1dMHd7Jjqbs/UtnssoHeaVM3Qgjr7Dxumrn544VpZ9SIK6XIcKO+6oNxsNz0u59t\njdizSY4MJNDXm0MufAwl0Avh4nYVN5AaF0J4YO/55/QRIRysaPbY611DuRAL4OWlSIsPcemeNxLo\nhXBhWmt2Hm9g6siIPvfJiA+lub2biqb2YRyZ89hf1kRMiB9xZ1kMvD9pca79qUgCvRAurLiujdqW\nTqaN6jvQW3LMnpqnzytrYkJC2JAaDKbHh1DV3EFjq2tW3kigF8KF7Sw25eenjez7ImHPyhtP09LR\nzeHKZqYkDS4/b2F5s3TV3vQS6IVwYTuPNxDk5016fEif+0QE+REf5s+hCtfNMQ/WN8fq6DZq5oyL\nGdLrpJmPr6t+KpJAL4QL21ncwJSkcHy8z/6nnO6hlTeb8mvw8/EiJ2VoZZFJEYEE+3m77AxZCfRC\nuKj2LgN5ZY1MG9V/EMuID+VIVTMGo2dV3mwqqGX6qEgCfL2H9DpKKdLiQznsopU3EuiFcFF55U10\nGfRZL8RapI8Ipb3LSHFd6zCMzDnUnujgQHkTc1NtMyM4PT6EI5KjF0IMp53HGwCYdpbSSosMS+WN\ni6YeBmNzQS0Ac1OHlp+3SI8PpeZEJ7UnOmzyesNJAr0QLmrn8XqSIgKJC+u/YZ3lYuJhF72YOBib\nC2oI9fcZcsWNhWW1KVdM30igF8JF7TzewFQr0jYAQX4+jIoK4qAHndFvyq/lnLHR/V6otpalsskV\n0zcS6IVwQVXN7ZQ2tFmVtrFIjw/1mDP64rpWjte12iw/DzAiLIDQAB+XrF6SQC+EC9plyc9beUYP\nkDEihGM1LXR0G+w1LKexuaAGsF1+HkyVN+kuWnljVaBXShUqpfYqpXYppXLN26KUUp8opY6Yv0ea\ntyul1NNKqXyl1B6lVLY9fwEhPNHO4gZ8vdWAOjJmjAij26g5VtNix5E5h6/ya4kN9Sctru+JZIOR\nHh/C4cpmjC5WpjqQM/r5WuupPVYcfwhYr7VOA9ab7wNcDKSZv+4CnrPVYIXn+uZYHX9Zd8jj6sD7\nsut4AxMSwgZUH57hIT1vtNZ8XVDD3HHRQ+pv05tZY6NpaO0it6jepq9rb0NJ3SwDXjbffhm4vMf2\nV7TJFiBCKZUwhJ8jPNxbucXc+MIWntmQz9Fq1/vYbGsGo2Z3ScOA8vMAY2KC8fFSLpljHohDlc3U\nnOhkjg3TNhYXTogn0NebNbtKbf7a9mRtoNfAOqXUdqXUXeZt8VrrcvPtCiDefDsJKO7x3BLzNiEG\nxGjUPLb2IA+s2sPYGEvFgwT6w5XNtHYarJoR25OfjxdjY4PdvufNpnzb1s/3FOzvw6KJ8Xy4t5zO\nbqPNX99erA3087TW2ZjSMvcqpc7r+aA2rWgwoM/USqm7lFK5SqlcWRdWnK6t08C9r+3guc8KuH7m\nKFbdPRulcOnFH2xlV/HAL8RaeELPm835NaREB5EUEWiX1182NZGG1i6+yneduGVVoNdal5q/VwHv\nADOBSktKxvy9yrx7KTCyx9OTzdtOf80VWuscrXVObGzs4H8D4Xaqmtq5dsXXrN1fwS8vncDvrphM\naIAvIyODXLKG2dZ2Hq8nKtiPUVFBA35uRnwox+taae3stsPIHK/LYGTL0Vq7nM1bnJsWS0SQL2t2\nldntZ9hav4FeKRWslAq13AYuAvYB7wG3mHe7BVhjvv0ecLO5+mYW0NgjxSPEWeWVNbHs2U3kV53g\nHzflcMe5Y09eUEuLCyFfUjcnV5QazIXG9BGWha7d8zjuKWmgpdNg10Dv5+PFJVMSWLe/0mXeMK05\no48HvlJK7Qa+AT7UWq8F/gAsUkodAS403wf4CDgK5AP/AO6x+aiFWzIaNd9/eRsAb/1wNhdOjD/l\n8dT4EI5Wt9BtcJ3cqK01tXeRX31iwBdiLdy98mZTfi1Kweyxtpso1ZtlWYm0dRn4JK/Srj/HVnz6\n20FrfRTI6mV7LbCwl+0auNcmoxMeZW9pI+WN7TxxbVav9eFpcaF0GowU17cxJibYASN0vD3FjWiN\n1a0PTjcyKogAXy+3bW62Kb+GiQlhRAb72fXnzEiJIjE8gDW7ylg21flrTWRmrHAa6w9W4aXg/PS4\nXh9PNU9+cdXFH2xh5/F6lIKsQZ7Re3spt70g29rZzY7j9cyzY9rGwstL8Z2piXxxuJq6lk67/7yh\nkkAvnMbGg1VMGxVJVB9nYycDvQfn6XcWN5AaG0JYgO+gXyM9PtQtUzfbCuvpMmi71M/3ZllWEt1G\nzUd7nf8SpAR64RSqmtrZW9rIgvG9n80DhPj7kBge4LEXZLXW7Co2XYgdioz4UKqaO6h3gTPRgdic\nX4Ovt2LGEJcNtNaEhFDS4kJ4zwWqbyTQC6ew8ZCpOnfhhL4DPUCqeUk8T3S8rpW6ls4BT5Q6naXy\nxt3SN5sKapg2KpIgv34vPdqEUoplUxP5prCO0oa2YfmZgyWBXjiF9QeqSAwPOFkV0hdLiaWrNZWy\nhZ2D6FjZm4x49wv09S2d7C9rYu644UnbWFyWZboQ+/5u5z6rl0AvHK6j28BX+TUsmBDXb214WlwI\n7V1Gpz+Dsoedx+sJ8vMmvZ83w/7Eh/kTFuDjNpU3Wmte33YcrWFemn3LKk83KjqIaaMinH7ylAR6\n4XBbj9bR2mk4a37eIs2FV/kZCq01Gw9VMyMlCm+voXVkVEqRMSKUw27Q86aisZ3vv5zLH9ceYs64\naLKSh/ZpZzCWZSVyoLzJqT8hDU8yy0PVt3RS2tBGSX0bpQ1tlNa3UdrQSn1LF79aNokJCWGOHqJT\n2HCwigBfL+ZY8bE7NfbbmZ0Lxsf3s7f7OFjRzPG6Vn54/jibvF56fCgf7ClHa23zVr7DQWvNqu0l\n/PqDPLoMRv5v6URunZOC1xDfBAfj0sxEfv1BHu/tKuP+xRnD/vOtIYHeTv708UGe3VhwyrZAX2+S\nIgMprGnhnZ2lEugx/cGuP1jJ3HExVvVWDw/yJS7U3+NKLNfuq0ApWDTRNm9uGSNCeXXrcSqbOhgR\n3v/i4s6korGdh1fvYeOhamamRPHHqzJJceAEuthQf+amxrBmdyk/uyjdKd84JdDbQXuXgf9sOc6s\nsVHcOieFpIggkiIDiQzyRSnFdSu+ZlN+jaOH6RQKqk9QXNfGD86z/kw1LT7E4wL9x/sryBkdSWyo\nv01eb/wI00nG3tJGlwr07+8u4+fv7KXboHnkOxO5ebZjzuJPt2xqEve/tZsdxxuYPnp4yjsHQnL0\ndvBJXiWNbV3cOz+VJZMTmJIcTlSw38l3+nmpMewva3KJGXX2tv6AqazSmvy8RVpcKPmVzZi6bbi/\notoWDlY0s3jSCJu9ZtbIcIL9vPnsUFX/OzuJhtZOfvbWbsbFhrD2J+dy69wxThHkARZPisfHS/Hp\nAefsfSOB3g7ezC0mKSKwz1Ivy8y9rwtqh3NYTmnDwSrGjwglcQC9w8fFhdDSaaC8sd2OI3MeH++v\nALBpoPf38ebctFg2HKxymTfM1TtK6ew28vvvTmF0tHP1OgoN8GVSUjjbC51ziUEJ9DZWUt/KV/k1\nXDU9uc+zjcykcEL9fdhU4Nnpm0bz2pv9TZI6nWXBZ0+ZIfvx/komJoQxchD9589mwfg4yhvbOVDu\nvNUiFlpr3th2nKyREU57bStndCS7Shro6DY4eihnkEBvY29vN62xctX05D738fH24pyxUWz28Dz9\n50eqMRj1gKtn0jyo501VUzvbi+pZMtl2Z/MWF4w3Lfiz0QXSNzuON3C48gTXzxjZ/84OMiMlks5u\nI/tKmxw9lDNIoLcho1Hz1vZi5o6L6ffsa864GAprWympbx2m0TmfjQeriAr2G3DvlugQf6KC/cj3\ngFr6deZ+57ZM21jEhQaQmRzOeifNK/e0cttxgvy8WZqV6Oih9Gn66CgAcgvrHDySM0mgt6Gvj9ZS\nUt/G1Tl9n81bWFbA2ZzvmXl6g1Hz2aEqLkiPHdQEoNS4ELddJamnj/dXMCYmmHTzRDFbWzA+jp3F\nDU5dGNDc3sX7u8u5LCuREH/nLRSMDfUnJTqI3CLny9NLoLehlduKCQvwsersKz0+hJgQf4/N0+8q\nrqe+tYv5A6i26SktzlRi6SoXEgejsbWLrwtquWhSvN1qsxeMj0NrnLr65r3dZbR1Gbhu5ihHD6Vf\nOSlR5BbWOd3/Swn0NtLY2sXa/RVcPi3Jqok/SinmpkazuaDW6f5TDIf1B6rw9lKclz64heHT4kJo\nbOui+kSHjUfmPDYcqqTbqO2StrGYnBhObKg/6w86b6B/45tixo8IJSv5zFXHnE3O6EjqW7soqG5x\n9FBOIYHeRtbsNpV+XZNj/cWiueNiqG7u8IiLiqfbcLCKGSmRhAcObgGNNHNjr3w3Tt+s3VdBfJg/\nU+3Yv8XLS7EgI44vDlfT5YRr8e4rbWRvaSPXzRjplDNOT5eTYsrTby9yrjy9BHobeTO3mIkJYUxO\nsv6sY06qqdPeV0c8K31T2tDGwYrmAU2SOp27V960dRr4/HA1F00cYfdJQfPHx9Hc3k2uE9aAr9xW\njL+PF1dM6/+6lzMYFxtMZJAv25zsWEqgt4H9ZY3sK23iGisuwvaUHBnE6OggNntYnv6Lw9UAzM8Y\nfKCPDTW12nXXLpafH66mvctol7LK081Li8HP28vpyizbOg28u6uUS6YkEB40+KUTh5NSiumjo9hu\n5QXZ/GG6ziSB3gbeyi3Bz9uLy6cNfDX4OeNi2Hq0jm4n/NhsL7mF9UQH+51cA3YwlFKkxYe6beXN\nuv0VhAf6MnNMlN1/Voi/D+eMjXK6MssP95bT3N7NdU5cO9+bGSmRHKtpobr57NePyhvbuOiJz3nh\ny2N2H5ME+iFq7zLwzs5SLpoUT0RQ74tan83c1GiaO7rZU9poh9E5p+1FdWSPjhxyztWy2pS76TIY\n+fRAJQsnxOHrPTx/ogvGx1FQ3UJRrfNcRHzjm+OMjQkeljc7W8oxr1nbX57+rdwSjBoummT/dtsS\n6IfI0sDs2kGedVh6sG/ykDx9dXMHhbWt5Nigw19qXAi1LZ1OXQM+GFuO1tLU3s0SO1bbnM5yvWSD\nk1TfHKlsJreonmtd5CJsT5OTwvHz8TrrNQ+jUbNyWzFzU6OHpW+PBPoh6q+BWX+igv2YmBDmMfX0\nltyl5axnKFLdtOfNx/srCPT1HnTp6WCMjg5mXGyw0wT6lduK8fFSXHmWViLOyt/Hm6nJEWw7S57+\nq/waShvauG7G8MwNkEA/BDUnOvgqv4Yrz9LAzBpzU6PZUdRAW6fzNUOyte1Fdfh5ezEpceg10ZYS\nS3e6IGs0atbtr+SCjFir5mPY0sIJ8Ww5WsuJju5h/bmn6+g28PaOEhZNjCcmxDb994fb9JRI9pc2\n9vk3/ca240QG+Q5L2gYk0A/J1qN1aA3zM4Z25jUnNYZOg5FcJ6u9tYftRfVMSQ63SRBLDA8g2M/b\nrS7Ivr7tOFXNHVyamTDsP3t+RhxdBm3Tcl+jUQ+4n9N7u8qob+1yiZmwfZmREkm3UbOruOGMx2pO\ndPBJXiVXZifj7zM8b+YS6Idg67Fagvy8B1Q735uZKVH4eCk2uXnfm/YuA/tKm2ySnwdT5U2qG12Q\nLaxp4dEPDjAvNYZLJg9/oM9JiSQ0wIcNB21TfVPV1M7NL33DvMc2Wl3Rc6Kjmz99fIis5HDOTR1c\nOtQZTB/Vd4Ozt7eX0GXQXDdz+KqJJNAPwZajtUwfHTnkyohgfx+mjYpw++UF95Y20mkw2nSptdS4\nULdI3RiMmp++uQsfb8Wfrs50yMpJvt5enJcey8ZD1RiNQ6vt3niwiiVPfUluUR1JEYH88t19VqWE\nnll/hKrmDn61bLLTrB41GOFBvqTHh5zR4Exr00XYnNGRpMaFDtt4JNAPUl1LJ4crTzBrbLRNXm9u\nagz7yhppaHWvCpKeLFUItgz0afEhVDZ10NjWZbPXdITnvyhgx/EGfrNsMgnh1q+2ZWsLx8dR3dzB\nvrLBlft2dBv49ft53PavbcSF+vPBj+fxzA3TqGhq588fHzrrcwuqT/DSpmNck5M84NbVzignJYod\nRfUYerxpfnOsjqM1LcOelpJAP0jfHDOlWWaNtU2N79zUGLQ2fUpwV9uL6hgbE0y0DS+wucNqU/vL\nGnnik8NcOiWBZVMd22/9/PRYlPp2Ld+BKKg+wRXPbualTce4dU4K7947l9S4ULJHRXLzrNG8/HUh\nO4/3XomiteaR9/YT4OvNg0vGD/G3cA45oyNp7ujmUMW3nzjf2FZMaIAPl04Z3tSc1YFeKeWtlNqp\nlPrAfH+MUmqrUipfKbVSKeVn3u5vvp9vfjzFPkN3rC1H6wjw9WJKkm3OPLKSIwjy83bbPL3Wmu1F\n9WTb8GweTAuFA065CElrZzdXPreZ3310gJY+0hYd3QZ+unI3EUF+PHr5ZIfXjEeH+JM9KvLkOrXW\n+mBPGUui8EyaAAAgAElEQVSf/oryxjZeuDmHRy6bdMoF9/sXZxAfGsDDq/f22jxtXV4lXx6p4X8v\nTHfZSpvTzTitwVljaxcf7S3n8qlJBPoNb0XVQM7o7wMO9Lj/GPCE1joVqAe+b97+faDevP0J835u\nZ+uxOqaPjsTPxzYfivx8vJg5Joqv3DRPf7SmhfrWLptdiLVIjgwk0NebvU44s3jrsTq2F9Wz4ouj\nLPzL53y4p/yMviaPrzvMocpm/nhlJpHBA59ZbQ/LpiZysKKZvDLrlsRr7zLw8Oq9pI8IZe1PzuPC\niWeWDIYG+PKbyydzsKKZFV8cPeP5v/kgj/T4EG6aPdomv4MzSI4MJD7M/2SDs3d3ldLRbRz05Mqh\nsCpKKaWSgUuBF8z3FbAAWGXe5WXgcvPtZeb7mB9fqBx9mmJjDa2dHKxo4pwxtsnPW5yfHsuxmhYK\na5xnGrqtbC+03USpnry8FAvGx/HR3gqna7P7dUEtft5evHbnOUSH+HHvazu4+aVvKKg2pZm+OVbH\nii+Pcv3MUYNegMUelmYm4uutWL2jxKr9P95fQXN7N8sXZxAfFtDnfosmxnPJlBE8tf4IR6u/TbU9\n//lRSurbeOSyScPW8mE4KKXIGf3tQiSvf3OcKUnhQ67SGwxrj+qTwIOA5S8pGmjQWls+j5YAlo5e\nSUAxgPnxRvP+p1BK3aWUylVK5VZXVw9y+I7xzTFT/fw5Nu7BYenm6Myr/QxWblEdEUG+jI2x/ZJ4\n381Ooq6lk88POdf/o80FNWSPjmDOuBje+9E8fnXZJHYVN7DkyS94bO1BfvbWLkZGBvHLSyc4eqin\niAr2Y35GHO/uKrOq2d6bucWMjAq0qjDhke9Mwt/Hi5+/sxetNcV1rfzts3wuzUw42Q7EneSkRFLW\n2M7afRUcrGge1pLKnvoN9EqppUCV1nq7LX+w1nqF1jpHa50TGzt8U71tYeuxOvx9vMiycWVASkww\nY2OC2eBkAcsWcovqmT4q0i4lc+elxxId7MfqndadgQ6HhtZO9pc1nQxe3l6KW+aksOFnF/CdzESe\n+6yAkvo2Hr8mi2AnXAf1u9nJ1Jzo4Mt+UonFda1syq/l6ukjrfq3jQsL4OGLJ7DlaB1v5hbz2w8P\n4KUUv7jEud7sbCXHvGD4I+/vJ9DXm8sctLi5Nf/D5gKXKaUuAQKAMOApIEIp5WM+a08GSs37lwIj\ngRKllA8QDrjVFcatx2qZNirCLlPUL8iI4z9bi2jt7CbIz/kCwGDUtXRytLqFK7Pt07fE19uLy6Ym\n8uqW4zS2djlF7/ItR2vRGuaMO/UsNzbUn8evncoN54yisa3r5IpEzmb++FgignxZvaP0rOsGvLW9\nBKUYUE+a62aM5N2dpTzyXh5tXQbuvyidxAjHlZTa04SEUIL8vKls6uCanGRCAxzzf7PfM3qt9cNa\n62StdQpwHbBBa30jsBG4yrzbLcAa8+33zPcxP75Bu9GiqI1tXeSV2T4/b7FgfByd3Ua+LnCf98Yd\nlkZmNr4Q29OV2cl0Gox8sLfMbj9jIDYXmGZN9/WpLyclioUThqfPyWD4+3jzncxE1u2voKm99zkK\nBqNmVW4x56bFkjSAQO3lpfjdd6dgMGpGRwdxx7ljbTVsp+Pj7UX2KNP/+2uHqYFZb4Zy5WM58FOl\nVD6mHPyL5u0vAtHm7T8FHhraEJ1LbmEdRg3n2Kh+/nQzxkQS5OftdKv9DEVuUT2+3srmqa6eJiWG\nkR4fwuodpf3vPAw2F9Qyc0yUS19c/G52Eh3dRv67t7zXxzfl11DW2D7gldXA1Hn09bvO4ZXbZw57\n87bhdt3MkXw3O4nsUY6bBDag3IDW+jPgM/Pto8DMXvZpB662wdic0tZjpu6LlndpW/P38WZuagwb\nD1ajtXZ4XbUtbC+qY1KibRqZ9UUpxXezk/nDfw9SWNNCSoz9e3z3paqpnfyqE4MKgM5k6sgIxsYG\n8/aO0l7PRt/MLSYiyJdFvZRTWmP6aOdMW9na0sxElmY6diKc655uOMjWo7VMHWmf/LzF/Iw4Shva\n3GLh645uA7tLGu2atrG4fGoSSsHqnY49q//aPLvZ1atIlFJcmZ3MN8fqKK47tQNlfUsn6/ZXcvnU\npGHrwCgGTwL9AJzo6GZfWZPd0jYW88ebqpA2OskiEEOxr7SJzm7bNjLry4jwAOalxrB6R8mQm3IN\nxeb8WsIDfZmQEOawMdiKZR3k01Nia3aV0mkwck2Oa63n6qkk0A9AbmEdBqO224VYi4TwQMaPCHWL\nPL3lQux0G0+U6st3s5MoqW87o2vgcNp8tIZZY6PwduHuixZJEYHMHhvN6p0lJ2f1aq1ZmVvClKRw\nJia6/puZJ5BAPwBbjtbh46XIHm3/iyrzx8eRW1jfZ8WDq8gtqmNUVBBxoX3PmLSlxZNGEOTnbfWs\nTlsrrmuluK7N5dM2PX03O4mi2lZ2mBuS7S9r4kB5k8tfg/AkEugHYOuxWjKTw4elvn3B+Di6jbZd\n7We4WRqZDUd+3iLIz4eLJyfw4Z5y2ruGf2nGzea1f0+vn3dlF09JIMDXi7fN6ZuV24rx9/HisqlJ\n/TxTOAsJ9FZq7exmb0kj59io/3x/po2MICzAx6Xz9EW1rdSc6By2tI3FldOTaO7o5pM826yUNBCb\nC2qJDfU/uXC5Owjx92HJpBF8sLuMxrYu1uwqZcnkEYQHOn5imrCOBHorbS+qp9uobbbQSH98zKv9\nfHZ46Kv9OIolTz4cF2J7mjUmmsTwgGFP32it2VxQy5xx0W5RFtvTd7OTaWrvZvmqPTS1d3OtXIR1\nKRLorbT1aB3eXmpYg9b8DNNqP/utbBfrbLYX1RMa4EP6MC6ZBqaZl1dkJ/HFkRqqmtuH7ecWVJ+g\nurnDrdI2FnNTY4gL9Wft/gqSI61rYCachwR6K205WsvkpHBChrEB1fkZptV+nKH65s1txby6teiM\nfup9Kag+wSd5FUwfbZ9GZv25YloyBqPmvV3D1xJhc4F71M/3xttLcYW51NLaBmbCeUigt0Jbp4Hd\nJQ3MsnFb4v7EhPiTmRzh8EDf3N7F/723j1+8s4/lb++hs/vsrWt3FTdw1XObAXhwsWOWhUuNCyFr\nZASrttsmfVPf0sk1f/+a17853uc+m/NrSY4MZGRUkE1+prP53qzRzM+I5fpzJG3jajwu0J/o6GZ7\nUZ3VZ6YAO4/X02XQdp8o1Zv5GbHsKm6grsVxi4Z/tLec9i4jy6Ym8mZuCTe/tLXPRcw/O1TF9Su2\nEBrgy6ofznFonfV3pyVxsKKZw5VDW2ZQa83yt/fwTWEdP39nL2t2nTnz1mjUfH201i3TNhYjo4L4\n520zh61UVtiOxwX6Jz45zJXPfc0lT3/Fh3vKT1mh/XQGo2b9gUoe+/gQXgqHtJRdMD4OreHzw447\nq38rt4TUuBCevHYqT1ybxY6iBq742+ZTVgkCeHdnKXe8nEtKTDCr7p7t0H4zABdPGYFS8OGe3pty\nWeu1b46zLq+S+y9KZ0ZKFD97czefHz51zYC88iYa27rcMm0jXJ9HBXqtNevyKsiID6Wj28C9r+3g\noic+Z/WOklNW0mls7eIfXxxl/p8/4/sv51LR2MZvr5hCmAN6SU9ODCcmxI+NBx2zGMmxmhZyi+q5\nanoySimumJbMa3eeQ2NbF1f8bfPJdsovfHmUn6zcRU5KJCt/MMspzvriQgM4Z0wUH+wpG9AnuJ6O\nVDbzmw/yODcthnsuSOWFW3JIiw/lh//efnICEXxbPz/bjc/ohevyqEB/pOoExXVt3DxnNJ/87/k8\ne0M2vt5e/PTN3Sz4y+f8a9MxHl69h3N+/ym//egAI8IDePaGbL5avoDrZzqml7SXl+L89Dg+P1x9\n1k8f9vL29hK8FCcvxIHpk82798wlNtSfm17cyl2v5PLohwe4ZMoI/nXbTIe8IfZlaWYiBdUtHBpE\n+qa9y8D/vLGLYD8f/nJNFl5eirAAX16+fQZxYf7c/q9tHDG/7uaCWlLjQs66ZqoQjuJRgf7TA6YJ\nNAvHx+Ptpbg0M4H/3ncuL9ycQ2SwH4+8n8c7O0u5YloSH/3Pubz5g9lcmpng8J7i88fH0tjWdcoZ\n5HAwGDVv7yjh/PTYMwLYqOgg3r57DrPHRbMur5LvzRrFM9dnO11v8SWTR+Cl4IPdA0/f/HHtIQ6U\nN/GnqzNP+YQSFxrAv28/B19vL2568RuKalv45lidW+fnhWtzj7XqrLT+QBWTk8IYEf7tH61Sigsn\nxrNwQhx55U0kRQQSEeTnwFGe6fz0WAJ9Tf1bZgzjdYLNBTWUN7bzy0sn9vp4eKAv/7x1BgfKm5mc\nFOaUk4RiQvyZMy6GD/eW87OL0q0e48ZDVby06Ri3zklhwfgz+62Pig7ildtncs3zX3P5s5to7TRI\noBdOy2PO6GtPdLDjeD0Le/mjBVPAn5QY7nRBHiA0wJelmQm8t6uMlo7uIb9et8FoVRpo1fYSwgN9\nWTih7zVDfby9mJIc7pRB3uLSzASO1bRYPfGsurmDB97aTUZ8KA9d3Hd56ISEMF66dQatnQaUwu5d\nTYUYLI8J9BsPVaM1XOjE63SezXUzR9HSaeD93QOfANTeZeDrglqe+vQI33thK1MeWcc1z3991nr4\npvYu1u6r4LKsRKdLxwzU4kkj8PZSfNjHkng9GY2a+9/aTXN7N09fP63f331GShSv3D6TRy+fTGSw\n850kCAEelLpZf6CS+DB/Jie5Zv/s7FERpMeH8Pq2Yq6z4sJwR7eBv392lC+PVLO7pIEug0YpGD8i\njIsmxbNmVxl/+O9B/u87vadlPtxTTke3kaumu34r2qhgP+amxvDhnnIeXJxx1k8f/9laxOeHq/nN\nsklkjLCudcM5Y6OHrdmdEIPhEYG+o9vAF4eruWxqklOnGM5GKcV1M0bx6w/yOFDe1O/qRf/cVMgT\nnx5m6sgIbp83hpkpUeSMjiI8yFQRExnkx0ubjnHO2CgWTxpxxvNXbS8hPT6EzORwu/w+w23plAQe\nfHsPe0sbyUzufT2BqqZ2/rj2EOemxfC9WaOHeYRC2I9HpG62Hq2jpdPAhWfJNbuCK6Yl4eftxcpt\nxWfdr7G1i79tzGd+Rizv3juXhy+ewMIJ8SeDPMDDl4wnMzmc+9/afcZ6oAXVJ9jeo3beHSyeNAJf\nb3XWyVO/+fAAnQYjv1k22W1+byHAQwL9+gOVBPh6MTfVtWctRgb7sWTyCFbvKDnrohp//6KA5o5u\nHjhLnxl/H2+evSEbgB+9tuOUfP3b20vw9lJc7kYLS4QH+TIvNYYP9pT3OnnqyyPVvL+7jHsuGOfw\nGb1C2JrbB3qtNZ8eqGJeaozLX1QEuG7mSJrau/nvvt7PTCub2vnnpmMsy0rst8/MyKgg/nRVFrtL\nGvndRwcAU+386h2lnJ8eS5ybTf65NDOR0oY2dhU3nLK9vcvA/63ZT0p0ED88f5yDRieE/bh9oD9U\n2UxpQxsLXbTa5nSzx0aTEh3EG9/0nr558tMjGIyany7KsOr1lkwewW1zU/jX5kLW7itnU34NFU3t\nbnER9nSLJsbj5+11RvpmxRdHOVbTwm8un+wWJwNCnM7tA/36A6ZmYAvHu3Z+3kIpxbUzRrH1WN0Z\nTcWOVp/gzdxibpg5ilHR1rfKffjiCWQlh/PAqj387bN8IoLOXjvvqsIDfTkv3TR5yrJqV1FtC3/d\nmM/SzATOTYt18AiFsA+3D/SfHqgkMzncrdIQV05PwsdLnXFR9i/rDuPv48WPFqQN6PX8fLz46w3Z\nKGDL0TqWZSXi7+OeZ7ZLMxMpb2xnZ3E9Wmv+b81+/Ly9+P+W9l5mKoQ7cOlA39zeddYFoGtOdLCr\nuKHP2bCuKi40gIUT4li1veTkRdQ9JQ18uLecO+aNITbUf8CvOTIqiMevmUp8mD83nOO+pYULJ8Th\n5+PF+7vL+e++Cj4/XM1PF6VLMzLh1lw60P/98wLufCWXJz893GslxYaDVWiNW6Yhrps5itqWzpON\n2v649hCRQb7ced7YQb/mhRPj2fLwQqsnCrmi0ABfLkiP5cO95fz6/TwmJoRx82z3fWMTAlx8wtT/\nLEyjorGDJz89wrGaFh67MvOUi2nrD1SSEB7AJAeucmQv56XFkhQRyBvbigkL8OWr/Bp+eekEQofY\nItgT6seXZiWyLq8SpeC572Xj4+DupELYm0sHen8fb/58dSZjY4P508eHKK5rZcXNOcSE+NPeZeDL\nIzVcMc11Z8OejbeX4uqcZJ5af4SS+laSIgJlNqeVFo6PIyzAh2VTk5g2KtLRwxHC7vo9lVFKBSil\nvlFK7VZK7VdK/cq8fYxSaqtSKl8ptVIp5Wfe7m++n29+PMWev4BSinvnp/K3G7PZX9bE5c9u4nBl\nM1uO1tLaaXDZJmbWuCbHtEjz0eoW/ndRupQGWinY34fPH5jPI5dNcvRQhBgW1nxm7QAWaK2zgKnA\nEqXULOAx4AmtdSpQD3zfvP/3gXrz9ifM+9ndJVMSePMHs+noNnLl3zbz7MZ8An293Xppt8SIQBZP\nHMHEhLBTVoAS/YsM9sPby/0+6QnRm34DvTaxFGz7mr80sABYZd7+MnC5+fYy833Mjy9Uw5Q7yRoZ\nwZp755IcFcS2wnrmpbnHbNizefr6aay+Z44ELSFEn6zK0SulvIHtQCrwLFAANGitLatglACWU8ok\noBhAa92tlGoEooGa017zLuAugFGjbLcea2JEIG/9cDZPrz/C0swEm72us/LzkQuJYhC0Bm0EowG0\nAYzd5tvmbcZu83bL48bT7pv37fkaJ2+b9z3lZxh7bDeaHjtle29f5uej+3lM97Lv6Y/3uA3f7nNy\nWx/7nf74yW29Paa/Pban3Kbv1wTIvgVSF9r4H/hUVgV6rbUBmKqUigDeAfrulmUlrfUKYAVATk6O\nTVe9DvH34eeXTLDlSwpPZjRA5wnobIGuNjB0QndHj+8dYOgy3Td0mb6Mlvvd5iDa9W0wNVhud38b\nVPu6r429PNYzEFvu93ieJRCfHrBP38dtKVBeoJT5tvl+b7dRoPp4DuZPydZsO/kaqscYetzu+ZzT\nn99+au8lexhQ1Y3WukEptRGYDUQopXzMZ/XJQKl5t1JgJFCilPIBwoFaG45ZiMHR2vRH1VQOzeXQ\nWtvjq870va0O2uqhwxzYO09AV2v/rz0Qygu8fMHLu8d3nx5fXqdt9wbV47aXD/j4fbu/8j7zOcrb\nfLuX556yj9ep+5/87nXaz7Zs8z51X+Vleo2e+1i2n3zs9G09bvf5pczP6RGcTwbonvv03NYzuIqe\n+g30SqlYoMsc5AOBRZgusG4ErgLeAG4B1pif8p75/tfmxzfo3mYzCWFrWsOJSqg7+u1XfZEpqDeV\nQXMFdLf18kQFQVEQGAVB0RCWBP6h4BcMfiE9bgeDTyD4+Ju+vP1NAdfbH7x9wdvP/OVjCrrefqbt\nloDs7fttcBViGFlzRp8AvGzO03sBb2qtP1BK5QFvKKUeBXYCL5r3fxH4t1IqH6gDrrPDuIUn09oU\nvCv2QsUeqNgHtflQdwy6Wr7dT3lDeLIpcCdlQ2iC6SvM/D04zhTgA8JNZ5lCuKl+A73Weg8wrZft\nR4GZvWxvB662yeiEAFOqpXgrlOaag/teU5rFIjIFYsfDmPMgaixEjTF9Dx9pOosWwsO59MxY4YYM\n3VCVZwrslq+G46bHvP0hbgJkXAIjMmHEFIifBAHu1+JCCFuSQC8cy2iEyn1Q+CUc+wKKNkNHk+mx\n0AQYeQ6cc7fp+4gpppy4EGJAJNCL4aU11BbA0Y1w7HMo/MpU5QIQnQqTr4TRc2HUOabUi1RRCDFk\nEuiF/bXVm87WCzZA/gZoNKdiwkdCxqUw5lxIORfCpY2DEPYggV7YntamC6aH/gv5n5ouomoj+IeZ\nLpjO+wmMmw+RY+SMXYhhIIFe2EZ3hykNc+i/pq+mEkCZyhrPvR/GLYDkHKmCEcIBJNCLwTN0w5F1\nsGcl5K+HzmbwDTIF9fkPQ9piCJEFt4VwNAn0YuBq8mHnv2H366aZqMGxMOVKU9njmPPAN9DRIxRC\n9CCBXlinswX2v2sK8Me/Ns06TV8M026CtEWSkhHCiUmgF2fXcQK2/QM2PW1q+BWdChf+CrKug9AR\njh6dEMIKEuhF7zpbYdsLsOkpaK2B1EUw739h9ByplBHCxUigF6fqaoPcf8JXT0BLlenC6gUPw8gz\n2hoJIVyEBHphojXsexs+/gWcqDBdVL3gFRg929EjE0IMkQR6AY2l8OFP4fBaSJwGV70IKfMcPSoh\nhI1IoPdkRiNsfwk+ecS0vNxFv4VZd0tvdiHcjAR6T1WTD+/9GI5vhjHnw3eeMvVxF0K4HQn0nkZr\n2PI3+PRX4BsAy56FqTdKJY0QbkwCvSfpaof374M9b5i6Ri59AkLjHT0qIYSdSaD3FM2VsPJGKNkG\n838B5z0gZ/FCeAgJ9J6gfDe8fr2pL/w1r8DEZY4ekRBiGEmgd3d5a+CdH0JgFNy+FhKyHD0iIcQw\nk0DvrrSGz/8In/0OkmfAta9KPl4IDyWB3h0ZuuGDn5g6TWZdD0ufNFXYCCE8kgR6d9PVDqvvgAPv\nw3kPwvyfy0VXITycBHp30tEMb9xgWoh7yR9Ms1yFEB5PAr27aKmFV6+E8j1wxfOmfvFCCIEEevfQ\nWAL/vgIajsN1r0HGEkePSAjhRCTQu7qaI/DK5dDRBN9bDSlzHT0iIYSTkUDvyoq3wWvXmLpN3voh\nJGQ6ekRCCCfk5egBiEE6tBZe/g4EhMPtH0uQF0L0qd9Ar5QaqZTaqJTKU0rtV0rdZ94epZT6RCl1\nxPw90rxdKaWeVkrlK6X2KKWy7f1LeJztL8Mb10PcePj+JxA9ztEjEkI4MWvO6LuBn2mtJwKzgHuV\nUhOBh4D1Wus0YL35PsDFQJr56y7gOZuP2lNpDZ89Bu//D4ydD7d8ACGxjh6VEMLJ9RvotdblWusd\n5tvNwAEgCVgGvGze7WXgcvPtZcAr2mQLEKGUSrD5yD2NZbbrZ78zzXa9YSX4hzh6VEIIFzCgi7FK\nqRRgGrAViNdal5sfqgAsjVSSgOIeTysxbytHDE5nK7x9Bxz6EOb9FBb+n8x2FUJYzepAr5QKAd4G\nfqK1blI9Ao3WWiul9EB+sFLqLkypHUaNGjWQp3qWE1Xw+nVQugMu/hOcc5ejRySEcDFWVd0opXwx\nBflXtdarzZsrLSkZ8/cq8/ZSYGSPpyebt51Ca71Ca52jtc6JjZU8c6+qD8MLF0JlHlz3qgR5IcSg\nWFN1o4AXgQNa68d7PPQecIv59i3Amh7bbzZX38wCGnukeIS1Cr+CFy+Erla47UMYf6mjRySEcFHW\npG7mAjcBe5VSu8zbfg78AXhTKfV9oAi4xvzYR8AlQD7QCtxm0xF7gj1vwrv3QNRYuPFNiExx9IiE\nEC6s30Cvtf4K6OvK38Je9tfAvUMcl2fSGr78M2x4FFLOhWv/DYGRjh6VEMLFSQsEZ6E1fPgzyH0R\nMq+Fy54BH39Hj0oI4QakBYIz0Bo+esAU5OfeZ2ozLEFeCGEjEugdTWtY+zBs+wfM+TFc+CupkRdC\n2JQEekfSGtb9ErY+B7PugUW/kSAvhLA5CfSOojWs/xV8/VeYeRcs/p0EeSGEXUigd5SNv4OvnoDp\nt8HFf5QgL4SwGwn0jvDZY/DFH2HaTXDp4xLkhRB2JYF+uH3zD3MHyhvgO0+Dl/wTCCHsS6LMcDq0\nFv77IKQvMdXJS5AXQgwDiTTDpWwnrLoNRmTCVS+Bt8xVE0IMDwn0w6HhOLx2LQRFmxYM8Qt29IiE\nEB5ETivtra0BXr0Gutrh5jUQOsLRIxJCeBjPO6PX2rRi03Do7oQ3b4LafFODsrgJw/NzhRCiB88L\n9Bt/B4+Nhv8uN63eZC9aw/v3wbEvTBdex55vv58lhBBn4VmBvrkSNj8DYYmmMsensuDTR6C1zrY/\np3yP6cLr7tfggodh6vW2fX0hhBgAz8rRf/UEGDrhe+bVEDf+Dr56Era9aGooNutu8A8d3GsbjXDk\nY/j6WSj8EnyD4bwH4Pzlthu/EEIMgucE+sZSyH3JdHYdPc607aoX4dyfwobfwsbfwpbnYOQ5EBwD\nwbGnfg+MBN8g8AkA30Dz9yAwdMDu103Prc2HsGRTc7LsmyEwwrG/sxBC4EmB/su/gDbCeQ+euj1+\nElz/GpRsh81PQe1RU817aw0Yu61//cRsuPJFmLgMvH1tO3YhhBgCzwj09UWw4xXTWXbk6N73SZ4O\n17zy7X2tob0BWmqgpdpUJtndBl3mr+52U8mkoRNSF5o+CUjPGiGEE/KMQP/FH0F5wXn3W/8cpUzp\nmsBIiEmz39iEEMLO3L/qprYAdr0OObebqm2EEMLDuH+g//wx0/qr8/7X0SMRQgiHcO9AX3UQ9rwJ\nM++E0HhHj0YIIRzCvQP9Z783NRCbc5+jRyKEEA7jvoG+Yi/kvWuaBBUc7ejRCCGEw7hH1Y2lFLK5\nAprKTN93vAIB4TD7R44enRBCOJRrB/odr5gmQjVXmOraT6Hgkj/J7FQhhMdz7UAfHAtJORCWAKEJ\npl7voYnm7yNMrQqEEMLDuXagz7jY9CWEEKJP7nsxVgghBGBFoFdKvaSUqlJK7euxLUop9YlS6oj5\ne6R5u1JKPa2UyldK7VFKZdtz8EIIIfpnzRn9v4Alp217CFivtU4D1pvvA1wMpJm/7gKes80whRBC\nDFa/gV5r/QVw+hJMy4CXzbdfBi7vsf0VbbIFiFBKJdhqsEIIIQZusDn6eK11ufl2BWDpL5AEFPfY\nr8S8TQghhIMM+WKs1loDeqDPU0rdpZTKVUrlVldXD3UYQggh+jDYQF9pScmYv1eZt5cCI3vsl2ze\ndgat9QqtdY7WOic2NnaQwxBCCNGfwQb694BbzLdvAdb02H6zufpmFtDYI8UjhBDCAZQp83KWHZR6\nHSPbbZEAAAMcSURBVLgAiAEqgf8HvAu8CYwCioBrtNZ1SikF/BVTlU4rcJvWOrffQShVbX6dwYgB\nagb5XHchx0COAcgx8MTff7TWut+USL+B3tkppXK11jmOHocjyTGQYwByDDz99z8bmRkrhBBuTgK9\nEEK4OXcI9CscPQAnIMdAjgHIMfD0379PLp+jF0IIcXbucEYvhBDiLFw60CulliilDpm7ZT7U/zNc\n30C6ibojpdRIpdRGpVSeUmq/Uuo+83ZPOgYBSqlvlFK7zcfgV+btY5RSW81/DyuVUn6OHqu9KaW8\nlVI7lVIfmO973DGwhssGeqWUN/Aspo6ZE4HrlVITHTuqYfEvrO8m6o66gZ9prScCs4B7zf/unnQM\nOoAFWussYCqwxDxB8THgCa11KlAPfN+BYxwu9wEHetz3xGPQL5cN9MBMIF9rfVRr3Qm8gal7plsb\nYDdRt6O1Ltda7zDfbsb0R56EZx0DrbU+Yb7ra/7SwAJglXm7Wx8DAKVUMnAp8IL5vsLDjoG1XDnQ\nS6fMb/XVTdStKaVSgGnAVjzsGJhTFrsw9Zn6BCgAGrTW3eZdPOHv4UngQcBovh+N5x0Dq7hyoBe9\nGGw3UVejlAoB3gZ+orVu6vmYJxwDrbVBaz0VU+PAmcB4Bw9pWCmllgJVWuvtjh6LK3DlxcGt7pTp\nASqVUgla6/LTuom6JaWUL6Yg/6rWerV5s0cdAwutdYNSaiMwG9NCPz7mM1p3/3uYC1ymlLoECADC\ngKfwrGNgNVc+o98GpJmvsvsB12HqnumJ+uom6nbMedgXgQNa68d7PORJxyBWKRVhvh0ILMJ0rWIj\ncJV5N7c+Blrrh7XWyVrrFEx/+xu01jfiQcdgIFx6wpT53fxJwBt4SWv9WwcPye4G0k3UUWO0J6XU\nPOBLYC/f5mZ/jilP7ynHIBPThUZvTCdrb2qtf62UGoupKCEK2Al8T2vd4biRDg+l1AXA/VrrpZ56\nDPrj0oFeCCFE/1w5dSOEEMIKEuiFEMLNSaAXQgg3J4FeCCHcnAR6IYRwcxLohRDCzUmgF0IINyeB\nXggh3Nz/D6uwc/gOX6CiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34911ea050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# since we are using stateful rnn tsteps can be set to 1\n",
    "tsteps = 1\n",
    "batch_size = 1\n",
    "epochs = 1000\n",
    "# number of elements ahead that are used to make the prediction\n",
    "lahead = 1\n",
    "\n",
    "\n",
    "def gen_cosine_amp(amp=100, period=1000, x0=0, xn=50000, step=1, k=0.0001):\n",
    "    \"\"\"Generates an absolute cosine time series with the amplitude\n",
    "    exponentially decreasing\n",
    "    Arguments:\n",
    "        amp: amplitude of the cosine function\n",
    "        period: period of the cosine function\n",
    "        x0: initial x of the time series\n",
    "        xn: final x of the time series\n",
    "        step: step of the time series discretization\n",
    "        k: exponential rate\n",
    "    \"\"\"\n",
    "    cos = np.zeros(((xn - x0) * step, 1, 1))\n",
    "    for i in range(len(cos)):\n",
    "        idx = x0 + i * step\n",
    "        cos[i, 0, 0] = amp * np.cos(2 * np.pi * idx / period)\n",
    "        cos[i, 0, 0] = cos[i, 0, 0] * np.exp(-k * idx)\n",
    "    return cos\n",
    "\n",
    "\n",
    "print('Generating Data...')\n",
    "cos = gen_cosine_amp()\n",
    "print('Input shape:', cos.shape)\n",
    "\n",
    "expected_output = np.zeros((len(cos), 1))\n",
    "for i in range(len(cos) - lahead):\n",
    "    expected_output[i, 0] = np.mean(cos[i + 1:i + lahead + 1])\n",
    "\n",
    "print('Output shape:', expected_output.shape)\n",
    "\n",
    "print('Creating Model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(50,\n",
    "               input_shape=(tsteps, 1),\n",
    "               batch_size=batch_size,\n",
    "               return_sequences=True,\n",
    "               stateful=True))\n",
    "model.add(LSTM(50,\n",
    "               return_sequences=False,\n",
    "               stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='rmsprop',validation_split=0.05)\n",
    "\n",
    "print('Training')\n",
    "loss = []\n",
    "val_loss = []\n",
    "for i in range(epochs):\n",
    "    print('Epoch', i, '/', epochs)\n",
    "\n",
    "    # Note that the last state for sample i in a batch will\n",
    "    # be used as initial state for sample i in the next batch.\n",
    "    # Thus we are simultaneously training on batch_size series with\n",
    "    # lower resolution than the original series contained in cos.\n",
    "    # Each of these series are offset by one step and can be\n",
    "    # extracted with cos[i::batch_size].\n",
    "\n",
    "    history = model.fit(trainX, trainY,\n",
    "              batch_size=batch_size,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              shuffle=False,validation_split=0.05)\n",
    "    loss.append(history.history['loss'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    model.reset_states()\n",
    "    \n",
    "# summarize history for loss\n",
    "plt.figure(0)\n",
    "plt.plot(loss,label='loss')\n",
    "plt.plot(val_loss,label='val_loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Predicting')\n",
    "predicted_output = model.predict(testX, batch_size=batch_size)\n",
    "\n",
    "print('Plotting Results')\n",
    "plt.figure(1)\n",
    "plt.plot(testY,label='expected')\n",
    "plt.plot(predicted_output,label='predicted')\n",
    "plt.legend()\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(expected_output)\n",
    "# plt.title('Expected')\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(predicted_output)\n",
    "# plt.title('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
