{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib qt\n",
    "from numpy.random import choice\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sequences_x_train shape:', (1000, 20, 1))\n",
      "('sequences_y_train shape:', (1000, 1))\n",
      "('sequences_x_test shape:', (200, 20, 1))\n",
      "('sequences_y_test shape:', (200, 1))\n"
     ]
    }
   ],
   "source": [
    "N_train = 1000\n",
    "X_train = np.zeros((1200,20))\n",
    "\n",
    "\n",
    "one_indexes = choice(a=N_train, size=N_train / 2, replace=False)\n",
    "X_train[one_indexes, 0] = 1  # very long term memory.\n",
    "Y_train = X_train[:,0]\n",
    "x_tr,y_tr = X_train[:1000,],Y_train[:1000,]\n",
    "x_ts,y_ts = X_train[-200:,],Y_train[-200:,]\n",
    "\n",
    "\n",
    "def prepare_sequences(x_train, y_train, window_length):\n",
    "    windows = []\n",
    "    windows_y = []\n",
    "    for i, sequence in enumerate(x_train):\n",
    "        len_seq = len(sequence)\n",
    "        for window_start in range(0, len_seq - window_length + 1):\n",
    "            window_end = window_start + window_length\n",
    "            window = sequence[window_start:window_end]\n",
    "            windows.append(window)\n",
    "            windows_y.append(y_train[i])\n",
    "    return np.array(windows), np.array(windows_y)\n",
    "X_train, y_train = prepare_sequences(x_tr,y_tr,20)\n",
    "X_test, y_test = prepare_sequences(x_ts,y_ts,20)\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "max_len = 20\n",
    "batch_size = 1\n",
    "print('sequences_x_train shape:', X_train.shape)\n",
    "print('sequences_y_train shape:', y_train.shape)\n",
    "\n",
    "print('sequences_x_test shape:', X_test.shape)\n",
    "print('sequences_y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact of subsequence subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (1000, 20))\n",
      "('X_test shape:', (200, 20))\n",
      "('sequences_x_train shape:', (1000, 20, 1))\n",
      "('sequences_y_train shape:', (1000, 1))\n",
      "('sequences_x_test shape:', (200, 20, 1))\n",
      "('sequences_y_test shape:', (200, 1))\n"
     ]
    }
   ],
   "source": [
    "USE_SEQUENCES = False\n",
    "max_len = 20\n",
    "batch_size = 1\n",
    "\n",
    "N_train = 1000\n",
    "N_test = 200\n",
    "\n",
    "X_train = np.zeros((N_train, max_len))\n",
    "X_test = np.zeros((N_test, max_len))\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "y_train = np.zeros((N_train, 1))\n",
    "y_test = np.zeros((N_test, 1))\n",
    "\n",
    "one_indexes = choice(a=N_train, size=N_train / 2, replace=False)\n",
    "X_train[one_indexes, 0] = 1\n",
    "y_train[one_indexes] = 1\n",
    "\n",
    "one_indexes = choice(a=N_test, size=N_test / 2, replace=False)\n",
    "X_test[one_indexes, 0] = 1\n",
    "y_test[one_indexes] = 1\n",
    "\n",
    "if USE_SEQUENCES:\n",
    "    max_len = 10\n",
    "    X_train, y_train = prepare_sequences(X_train, y_train, window_length=max_len)\n",
    "    X_test, y_test = prepare_sequences(X_test, y_test, window_length=max_len)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)  # input dim is 1. Timesteps is the sequence length.\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "print('sequences_x_train shape:', X_train.shape)\n",
    "print('sequences_y_train shape:', y_train.shape)\n",
    "\n",
    "print('sequences_x_test shape:', X_test.shape)\n",
    "print('sequences_y_test shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        if self.counter % max_len == 0:\n",
    "            self.model.reset_states()\n",
    "        self.counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build STATELESS model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/.virtualenvs/deeplearn/local/lib/python2.7/site-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/15\n",
      "1000/1000 [==============================] - 13s - loss: 0.1315 - acc: 0.9540 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 2/15\n",
      "1000/1000 [==============================] - 13s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 3/15\n",
      "1000/1000 [==============================] - 13s - loss: 0.0012 - acc: 1.0000 - val_loss: 8.6233e-04 - val_acc: 1.0000\n",
      "Epoch 4/15\n",
      "1000/1000 [==============================] - 12s - loss: 5.6840e-04 - acc: 1.0000 - val_loss: 4.6509e-04 - val_acc: 1.0000\n",
      "Epoch 5/15\n",
      "1000/1000 [==============================] - 12s - loss: 3.0010e-04 - acc: 1.0000 - val_loss: 2.5785e-04 - val_acc: 1.0000\n",
      "Epoch 6/15\n",
      "1000/1000 [==============================] - 12s - loss: 1.6582e-04 - acc: 1.0000 - val_loss: 1.4590e-04 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      "1000/1000 [==============================] - 12s - loss: 9.3940e-05 - acc: 1.0000 - val_loss: 8.3512e-05 - val_acc: 1.0000\n",
      "Epoch 8/15\n",
      "1000/1000 [==============================] - 13s - loss: 5.3990e-05 - acc: 1.0000 - val_loss: 4.8024e-05 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "1000/1000 [==============================] - 13s - loss: 3.1291e-05 - acc: 1.0000 - val_loss: 2.7682e-05 - val_acc: 1.0000\n",
      "Epoch 10/15\n",
      "1000/1000 [==============================] - 13s - loss: 1.8218e-05 - acc: 1.0000 - val_loss: 1.5956e-05 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "1000/1000 [==============================] - 14s - loss: 1.0749e-05 - acc: 1.0000 - val_loss: 9.6819e-06 - val_acc: 1.0000\n",
      "Epoch 12/15\n",
      "1000/1000 [==============================] - 14s - loss: 6.5127e-06 - acc: 1.0000 - val_loss: 5.9682e-06 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "1000/1000 [==============================] - 14s - loss: 3.9650e-06 - acc: 1.0000 - val_loss: 3.7251e-06 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "1000/1000 [==============================] - 15s - loss: 2.4024e-06 - acc: 1.0000 - val_loss: 2.2979e-06 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "1000/1000 [==============================] - 14s - loss: 1.4485e-06 - acc: 1.0000 - val_loss: 1.4039e-06 - val_acc: 1.0000\n",
      "___________________________________\n",
      "('Test score:', 1.403862938786915e-06)\n",
      "('Test accuracy:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print('Build STATELESS model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(max_len, 1), return_sequences=False, stateful=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=15,\n",
    "              validation_data=(X_test, y_test), shuffle=False, callbacks=[ResetStatesCallback()])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.title('model loss stateless')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()   \n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "print('___________________________________')\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build STATEFUL model...\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 43s - loss: 0.0459 - acc: 0.9758    \n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 45s - loss: 1.7573e-07 - acc: 1.0000    \n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 47s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 46s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 44s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 43s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 44s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 42s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 43s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 44s - loss: 1.0960e-07 - acc: 1.0000    \n",
      "Train...\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n",
      "accuracy training = 1.0\n",
      "loss training = 1.09604656018e-07\n",
      "___________________________________\n",
      "accuracy testing = 1.0\n",
      "loss testing = 1.09604663123e-07\n",
      "___________________________________\n"
     ]
    }
   ],
   "source": [
    "# STATEFUL MODEL\n",
    "print('Build STATEFUL model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(10,\n",
    "               batch_input_shape=(1, 1, 1), return_sequences=False,\n",
    "               stateful=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "x = np.expand_dims(np.expand_dims(X_train.flatten(), axis=1), axis=1)\n",
    "y = np.expand_dims(np.array([[v] * max_len for v in y_train.flatten()]).flatten(), axis=1)\n",
    "model.fit(x,\n",
    "          y,\n",
    "          callbacks=[ResetStatesCallback()],\n",
    "          batch_size=1,\n",
    "          shuffle=False)\n",
    "\n",
    "print('Train...')\n",
    "for epoch in range(15):\n",
    "    mean_tr_acc = []\n",
    "    mean_tr_loss = []\n",
    "    for i in range(len(X_train)):\n",
    "        y_true = y_train[i]\n",
    "        for j in range(max_len):\n",
    "            tr_loss, tr_acc = model.train_on_batch(np.expand_dims(np.expand_dims(X_train[i][j], axis=1), axis=1),\n",
    "                                                   np.array([y_true]))\n",
    "            mean_tr_acc.append(tr_acc)\n",
    "            mean_tr_loss.append(tr_loss)\n",
    "        model.reset_states()\n",
    "\n",
    "    print('accuracy training = {}'.format(np.mean(mean_tr_acc)))\n",
    "    print('loss training = {}'.format(np.mean(mean_tr_loss)))\n",
    "    print('___________________________________')\n",
    "\n",
    "    mean_te_acc = []\n",
    "    mean_te_loss = []\n",
    "    for i in range(len(X_test)):\n",
    "        for j in range(max_len):\n",
    "            te_loss, te_acc = model.test_on_batch(np.expand_dims(np.expand_dims(X_test[i][j], axis=1), axis=1),\n",
    "                                                  y_test[i])\n",
    "            mean_te_acc.append(te_acc)\n",
    "            mean_te_loss.append(te_loss)\n",
    "        model.reset_states()\n",
    "\n",
    "        for j in range(max_len):\n",
    "            y_pred = model.predict_on_batch(np.expand_dims(np.expand_dims(X_test[i][j], axis=1), axis=1))\n",
    "        model.reset_states()\n",
    "\n",
    "    print('accuracy testing = {}'.format(np.mean(mean_te_acc)))\n",
    "    print('loss testing = {}'.format(np.mean(mean_te_loss)))\n",
    "    print('___________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
